{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c688ae26-bef9-4988-9133-0346dc4eff32",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5075e9a-43ff-49f5-888b-342d5ecda78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import tqdm\n",
    "import os, time, math, copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_printoptions(precision=8, linewidth=50000)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b68ddb-8ef2-42a1-94c1-4f708b4907d7",
   "metadata": {},
   "source": [
    "# User Define Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "470d6312-f557-4f84-899f-95686b41e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '~/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c0a67-1a39-4ce3-913b-749c11f6878b",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa129a9b-9a85-4de6-b42a-f8cbfc31231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch for MNIST dataset')\n",
    "parser.add_argument('--device', type=str, default='cuda', help='Device')\n",
    "parser.add_argument('--shuffle', action='store_true', default=False, help='enables data shuffle')\n",
    "parser.add_argument('--dataset', type=str, default='mnist', help='training dataset')\n",
    "parser.add_argument('--data_path', type=str, default=data_path, help='path to MNIST')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=10, help='number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--loss_func', type=str, default='cel', help='optimizer')\n",
    "parser.add_argument('--quant_opt', type=str, default='asym', help='Type of Quantization')\n",
    "parser.add_argument('--num_bits', type=int, default=8, help='Number of Quantization Bits')\n",
    "parser.add_argument('--act_quant', type=bool, default=False, help='Activation Quantization')\n",
    "parser.add_argument('--disp', type=bool, default=False, help='Display Model Information')\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afa21c-b407-4698-bf0b-85e9dc4c94f1",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c82ac1a-0065-4d3f-a915-a01a91eb47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.device == 'cuda' else {}\n",
    "if args.dataset == 'mnist':\n",
    "\ttrain_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=True,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=transforms.ToTensor()\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)\n",
    "\n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=False,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=transforms.ToTensor()\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625782c6-b278-4485-a8c9-7c6fec5aafdf",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98354784-1637-4f2c-85b2-6b53f0805bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(MLP, self).__init__()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.fc1 = nn.Linear(28*28, 32)\n",
    "\t\tself.relu1 = nn.ReLU()\n",
    "\t\tself.fc2 = nn.Linear(32, 16)\n",
    "\t\tself.relu2 = nn.ReLU()\n",
    "\t\tself.fc3 = nn.Linear(16, 10)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.relu1(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\tx = self.relu2(x)\n",
    "\t\tlogits = self.fc3(x)\n",
    "\t\treturn logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ebfd9aa-9e7b-4638-8db1-101093cdfb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genOptimizer(model, args):\n",
    "\tif args.optimizer == 'sgd':\n",
    "\t\toptimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\tif args.optimizer == 'adam':\n",
    "\t\toptimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\treturn optimizer\n",
    "\n",
    "def genLossFunc(args):\n",
    "\tif args.loss_func == 'cel':\n",
    "\t\tloss_func = nn.CrossEntropyLoss()\n",
    "\treturn loss_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "451421ff-8f60-41fd-8a34-7922c281a936",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(output, target, topk=(1,)):\n",
    "\twith torch.no_grad():\n",
    "\t\tmaxk = max(topk)\n",
    "\t\tbatch_size = target.size(0)\n",
    "\n",
    "\t\t_, pred = output.topk(maxk, 1, True, True)\n",
    "\t\tpred = pred.t()\n",
    "\t\tcorrect = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "\t\tres = []\n",
    "\t\tfor k in topk:\n",
    "\t\t\tcorrect_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n",
    "\t\t\tres.append(correct_k.mul_(100.0 / batch_size))\n",
    "\t\treturn res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb8fe687-70b1-4f29-8dd4-316acae35dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epoch, args):\n",
    "\tmodel.train()\n",
    "\tloss_func = genLossFunc(args)\n",
    "\toptimizer = genOptimizer(model, args)\n",
    "\tmax_batch_index = int(np.floor(len(train_loader.dataset)/args.batch_size))\n",
    "\trunning_loss = 0\n",
    "\tfor batch_index, (image, label) in enumerate(tq(train_loader, desc='Train', leave=False)):\n",
    "\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\tpred = model(image)\n",
    "\t\tloss = loss_func(pred, label)\n",
    "\t\trunning_loss += loss.item()#*image.size(0)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\t\t\n",
    "\tprint(f'Epoch {epoch+1:<3d}: Avg. Loss: {running_loss/len(train_loader.dataset):.4f}', end = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29189102-050a-463a-bbb8-18ca4ab3700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, epoch, args):\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tloss_func = genLossFunc(args)\n",
    "\t\tloss, correct = 0, 0\n",
    "# \t\tfor batch_index, (image, label) in enumerate(tq(test_loader, desc='Test', leave=False)):\n",
    "\t\tfor batch_index, (image, label) in enumerate(test_loader):\n",
    "\t\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\t\tpred = model(image)\n",
    "\t\t\tloss += loss_func(pred, label).item()#*image.size(0)\n",
    "\t\t\tcorrect += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tloss /= len(test_loader.dataset)\n",
    "\tcorrect_rate = 100 * correct / len(test_loader.dataset)\n",
    "\tprint(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a37298e4-2310-43d0-8990-500051f14cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  : Avg. Loss: 0.0085\tAccuracy: 9176/10000 (91.8%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2  : Avg. Loss: 0.0039\tAccuracy: 9333/10000 (93.3%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3  : Avg. Loss: 0.0031\tAccuracy: 9428/10000 (94.3%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4  : Avg. Loss: 0.0026\tAccuracy: 9494/10000 (94.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5  : Avg. Loss: 0.0023\tAccuracy: 9533/10000 (95.3%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6  : Avg. Loss: 0.0021\tAccuracy: 9555/10000 (95.5%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7  : Avg. Loss: 0.0019\tAccuracy: 9579/10000 (95.8%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8  : Avg. Loss: 0.0017\tAccuracy: 9594/10000 (95.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9  : Avg. Loss: 0.0016\tAccuracy: 9621/10000 (96.2%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 : Avg. Loss: 0.0015\tAccuracy: 9624/10000 (96.2%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def main(model):\n",
    "\tfor epoch in range(args.epochs):\n",
    "\t\ttrain(train_loader, model, epoch, args)\n",
    "\t\ttest(test_loader, model, epoch, args)\n",
    "\tprint(\"Done!\")\n",
    "\treturn model\n",
    "\n",
    "model = main(MLP().to(args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba686105-d369-4871-9967-c1a00020d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcScaleZeroPoint(min_val, max_val, args):\n",
    "\tqmin, qmax = 0., 2.**args.num_bits - 1.\n",
    "\tif args.quant_opt == 'asym':\n",
    "\t\tscale = (max_val - min_val) / (qmax - qmin)\n",
    "\t\tif scale is not 0.:\n",
    "\t\t\tscale = 2**torch.round(torch.log2(torch.tensor(abs(scale))))\n",
    "\t\tinitial_zero_point = -min_val / scale\n",
    "\t\tif initial_zero_point < qmin:\n",
    "\t\t\tzero_point = int(qmin)\n",
    "\t\telif initial_zero_point <= qmax:\n",
    "\t\t\tzero_point = int(initial_zero_point)\n",
    "\t\telse:\n",
    "\t\t\tzero_point = int(qmax)\n",
    "#\t\tzero_point = int({initial_zero_point < qmin: qmin,  initial_zero_point > qmax: qmax, qmin <= initial_zero_point <= qmax: initial_zero_point}.get(True, False))\n",
    "\tif args.quant_opt == 'sym':\n",
    "\t\tscale = max(abs(min_val), abs(max_val)) / qmax\n",
    "\t\tzero_point = 0\n",
    "\treturn scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05404ac6-6668-4b14-8b87-2a834f81ca29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizeTensor(input_tensor, min_val, max_val, args):\n",
    "\tif not min_val and not max_val:\n",
    "\t\tmin_val, max_val = input_tensor.min(), input_tensor.max()\n",
    "\t\n",
    "\tqmin, qmax = 0., 2.**args.num_bits - 1.\n",
    "\tscale, zero_point = calcScaleZeroPoint(min_val, max_val, args)\n",
    "\t\n",
    "\tif args.quant_opt == 'asym':\n",
    "\t\tquant_tensor = (input_tensor / scale + zero_point).clamp(qmin, qmax).round()\n",
    "\tif args.quant_opt == 'sym':\n",
    "\t\tquant_tensor = (input_tensor / scale).clamp(qmax, qmax).round()\n",
    "\treturn \tdict(zip(['qTensor', 'scale', 'zero_point'], [quant_tensor, scale, zero_point]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0df0d2-9ffa-4e30-861a-fc9e25d77a27",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "r = S(q-Z) \\\\\n",
    "here, r: real-value, S: scale, q: quantized-value, Z: zero-point\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "805346c4-b07b-4c8c-b01b-c2780b475a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantizeTensor(qDict, args):\n",
    "\tif args.quant_opt == 'asym':\n",
    "\t\tdequant_tensor = qDict['scale'] * (qDict['qTensor'].float() - qDict['zero_point'])\n",
    "\tif args.quant_opt == 'sym':\n",
    "\t\tdequant_tensor = qDict['scale'] * (qDict['qTensor'].float())\n",
    "\treturn dequant_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "298d8275-94e1-46c9-a348-6777c737ec50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateStats(actTensor, stats, layerName):\n",
    "\t# dim=0 : find min/max in each col\n",
    "\t# dim=1 : find min/max in each row\n",
    "\tmaxValue = torch.max(actTensor, dim=1)[0]\n",
    "\tminValue = torch.min(actTensor, dim=1)[0]\n",
    "\t\n",
    "\tif layerName not in stats:\n",
    "\t\tstats[layerName] = {'max': maxValue.sum(), 'min': minValue.sum(), 'total': 1}\n",
    "\telse:\n",
    "\t\tstats[layerName]['max'] += maxValue.sum().item()\n",
    "\t\tstats[layerName]['min'] += maxValue.sum().item()\n",
    "\t\tstats[layerName]['total'] += 1\n",
    "\t\t\n",
    "\tweighting = 2.0 / (stats[layerName]['total']) + 1\n",
    "\t\n",
    "\tif 'ema_min' in stats[layerName]:\n",
    "\t\tstats[layerName]['ema_min'] = weighting*(minValue.mean().item()) + (1 - weighting) * stats[layerName]['ema_min']\n",
    "\telse:\n",
    "\t\tstats[layerName]['ema_min'] = weighting*(minValue.mean().item())\n",
    "\n",
    "\tif 'ema_max' in stats[layerName]:\n",
    "\t\tstats[layerName]['ema_max'] = weighting*(maxValue.mean().item()) + (1 - weighting) * stats[layerName]['ema_max']\n",
    "\telse: \n",
    "\t\tstats[layerName]['ema_max'] = weighting*(maxValue.mean().item())\n",
    "\treturn stats\n",
    "\n",
    "# Reworked Forward Pass to access activation Stats through updateStats function\n",
    "def gatherActivationStats(model, x, stats):\n",
    "\tx = model.flatten(x)\n",
    "\tstats = updateStats(x, stats, 'fc1')\n",
    "\tx = F.relu(model.fc1(x))\n",
    "\t\n",
    "\tstats = updateStats(x, stats, 'fc2')\n",
    "\tx = F.relu(model.fc2(x))\n",
    "\n",
    "\tstats = updateStats(x, stats, 'fc3')\n",
    "# \tx = model.fc3(x)\n",
    "\treturn stats\n",
    "\n",
    "# Entry function to get stats of all functions.\n",
    "def gatherStats(model, test_loader, args):\n",
    "\tmodel.eval()\n",
    "\tstats = {}\n",
    "\twith torch.no_grad():\n",
    "\t\tfor image, label in test_loader:\n",
    "\t\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\t\tstats = gatherActivationStats(model, image, stats)\n",
    "\n",
    "\tfinal_stats = {}\n",
    "\tfor key, value in stats.items():\n",
    "\t\tfinal_stats[key] = { \"max\" : value[\"max\"] / value[\"total\"], \"min\" : value[\"min\"] / value[\"total\"], \"ema_min\": value[\"ema_min\"], \"ema_max\": value[\"ema_max\"] }\n",
    "\treturn final_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29c589c5-7ca6-4a54-ab0a-ad637975dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeQuantOp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, min_val, max_val, args):\n",
    "\t\t#def quantizeTensor(input_tensor, min_val=None, max_val=None, num_bits=4, opt='asym'):\n",
    "        x = quantizeTensor(x, min_val, max_val, args)\n",
    "        x = dequantizeTensor(x, args)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # straight through estimator\n",
    "        return grad_output, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e137463-19bd-4209-8883-cfaae075f991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantAwareTrainingForward(x, model, stats, args):\n",
    "\twith torch.no_grad():\n",
    "\t\tparams = model.state_dict()\n",
    "# \t\tlayer_names, _ = zip(*list(model.named_modules())[1:])\n",
    "\n",
    "\tx = model.flatten(x)\n",
    "\t\n",
    "\tmodel.fc1.weight.data = FakeQuantOp.apply(model.fc1.weight.data, None, None, args)\n",
    "\tmodel.fc1.bias.data = FakeQuantOp.apply(model.fc1.bias.data, None, None, args)\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tstats = updateStats(x, stats, 'fc1')\n",
    "\tif args.act_quant:\n",
    "# \t\tx = FakeQuantOp.apply(x, stats['fc1']['ema_min'], stats['fc1']['ema_max'], args)\n",
    "\t\tx = FakeQuantOp.apply(x, None, None, args)\n",
    "\n",
    "\tx = model.relu1(model.fc1(x))\n",
    "\t\n",
    "\tmodel.fc2.weight.data = FakeQuantOp.apply(model.fc2.weight.data, None, None, args)\n",
    "\tmodel.fc2.bias.data = FakeQuantOp.apply(model.fc2.bias.data, None, None, args)\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tstats = updateStats(x.clone().view(x.shape[0], -1), stats, 'fc2')\n",
    "\tif args.act_quant:\n",
    "# \t\tx = FakeQuantOp.apply(x, stats['fc2']['ema_min'], stats['fc2']['ema_max'], args)\n",
    "\t\tx = FakeQuantOp.apply(x, None, None, args)\n",
    "\n",
    "\tx = model.relu2(model.fc2(x))\n",
    "\t\n",
    "\tmodel.fc3.weight.data = FakeQuantOp.apply(model.fc3.weight.data, None, None, args)\n",
    "\tmodel.fc3.bias.data = FakeQuantOp.apply(model.fc3.bias.data, None, None, args)\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tstats = updateStats(x.clone().view(x.shape[0], -1), stats, 'fc3')\n",
    "\tif args.act_quant:\n",
    "# \t\tx = FakeQuantOp.apply(x, stats['fc3']['ema_min'], stats['fc3']['ema_max'], args)\n",
    "\t\tx = FakeQuantOp.apply(x, None, None, args)\n",
    "\tx = model.fc3(x)\n",
    "\treturn x, params, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b5cabcd-e6c1-4e0b-8657-518ccd2238b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainQAT(train_loader, model, epoch, stats, args):\n",
    "\tmodel.train()\n",
    "\tloss_func = genLossFunc(args)\n",
    "\toptimizer = genOptimizer(model, args)\n",
    "\tmax_batch_index = int(np.floor(len(train_loader.dataset)/args.batch_size))\n",
    "\trunning_loss = 0 \n",
    "\tfor batch_index, (image, label) in enumerate(tq(train_loader, desc='Train', leave=False)):\n",
    "\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\ty = model(image)\n",
    "\t\ty, params, stats = quantAwareTrainingForward(image, model, stats, args)\n",
    "\t\t\n",
    "\t\t# Recover FP32 to improve accuracy\n",
    "\t\t# \t\tmodel.fc1.weight.data = params['fc1.weight']\n",
    "\t\tfor param, _ in model.named_parameters():\n",
    "\t\t\texec(f'model.{param}.data = params[\"{param}\"]')\n",
    "\n",
    "\t\tloss = loss_func(y, label)\t\t\n",
    "\t\trunning_loss += loss.item()#*image.size(0)\n",
    "\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\t\n",
    "\t\tif batch_index == max_batch_index:\n",
    "\t\t\tprint(f'[Epoch {epoch+1:>2d}] Training Loss: {running_loss/len(train_loader.dataset):.4f}', end = ' / ')\n",
    "\t\t\t\n",
    "\treturn stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef53312f-b91a-424b-bbb9-ca0fd6221e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQAT(test_loader, model, epoch, stats, args):\n",
    "\tcmodel = copy.deepcopy(model).to(args.device)\n",
    "\tcmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tloss_func = genLossFunc(args)\n",
    "\t\tloss, correct = 0, 0\n",
    "\t\tfor batch_index, (image, label) in enumerate(test_loader):\n",
    "\t\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\t\ty, _, _ = quantAwareTrainingForward(image, cmodel, stats, args)\t\n",
    "\t\t\tloss += loss_func(y, label).item()#*image.size(0)\n",
    "\t\t\tcorrect += (y.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tloss /= len(test_loader.dataset)\n",
    "\tcorrect_rate = 100 * correct / len(test_loader.dataset)\n",
    "\tprint(f'Test Loss:  {loss:>.4f} / Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa22d92e-c0b9-44a8-91f3-e2813dd43abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  1] Training Loss: 0.0092 / Test Loss:  0.0045 / Accuracy: 9163/10000 (91.6%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  2] Training Loss: 0.0041 / Test Loss:  0.0035 / Accuracy: 9323/10000 (93.2%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  3] Training Loss: 0.0033 / Test Loss:  0.0030 / Accuracy: 9437/10000 (94.4%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  4] Training Loss: 0.0029 / Test Loss:  0.0026 / Accuracy: 9501/10000 (95.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  5] Training Loss: 0.0024 / Test Loss:  0.0024 / Accuracy: 9560/10000 (95.6%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  6] Training Loss: 0.0022 / Test Loss:  0.0023 / Accuracy: 9586/10000 (95.9%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  7] Training Loss: 0.0020 / Test Loss:  0.0022 / Accuracy: 9595/10000 (96.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  8] Training Loss: 0.0018 / Test Loss:  0.0022 / Accuracy: 9604/10000 (96.0%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch  9] Training Loss: 0.0017 / Test Loss:  0.0022 / Accuracy: 9609/10000 (96.1%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 10] Training Loss: 0.0016 / Test Loss:  0.0021 / Accuracy: 9615/10000 (96.2%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def mainQAT(model):\n",
    "\tstats = {}\n",
    "\tfor epoch in range(args.epochs):\n",
    "\t\targs.act_quant = True if epoch > 5 else False\n",
    "\t\tstats = trainQAT(train_loader, model, epoch, stats, args)\n",
    "\t\ttestQAT(test_loader, model, epoch, stats, args)\n",
    "\tprint(\"Done!\")\n",
    "\treturn model, stats\n",
    "\n",
    "q_model, old_stats = mainQAT(MLP().to(args.device))\n",
    "# q_model, old_stats = mainQAT(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14cb7864-cdb1-43bb-8b1e-f3376692a96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.0021 / Accuracy: 9615/10000 (96.2%)\n"
     ]
    }
   ],
   "source": [
    "testQAT(test_loader, q_model, epoch=10, stats=old_stats, args=args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed7edb93-b3c1-4edc-8cb2-87b5fb58c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizeLayerForward(layer, x, args):\n",
    "\tc_layer = copy.deepcopy(layer).to(args.device)\n",
    "\twith torch.no_grad():\n",
    "\t\ty_wo_bias = c_layer(x) - c_layer.bias.data\n",
    "\n",
    "\t\tyDict = quantizeTensor(y_wo_bias, None, None, args)\n",
    "\t\twDict = quantizeTensor(c_layer.weight.data, None, None, args)\n",
    "\t\tbDict = quantizeTensor(c_layer.bias.data, None, None, args)\n",
    "\n",
    "\t\tc_layer.weight.data = wDict['qTensor']\n",
    "\t\tc_layer.bias.data = bDict['qTensor']\n",
    "\n",
    "\t\t# 64 x # of output nodes\n",
    "\t\txDict = quantizeTensor(x, None, None, args)\n",
    "\n",
    "\t\t# Int \n",
    "\t\tz1 = wDict['zero_point']\n",
    "\t\tz2 = xDict['zero_point']\n",
    "\t\tz3 = yDict['zero_point']\n",
    "\n",
    "\t\ta1 = torch.sum(wDict['qTensor'], dim=1)\n",
    "\t\ta2 = torch.sum(xDict['qTensor'], dim=1)\n",
    "\n",
    "\t\tq1 = wDict['qTensor']\n",
    "\t\tq2 = xDict['qTensor']\n",
    "\n",
    "\t\tm = wDict['scale'] * xDict['scale'] / yDict['scale']\n",
    "\t\tn = len(x)\n",
    "\n",
    "\t\tq1_q2_mul = torch.matmul(q1, q2.t())\n",
    "\n",
    "\t\ta1 = a1.view(a1.size(0), 1) * torch.ones(q1_q2_mul.size()).to(args.device)\n",
    "\t\ta2 = a2.view(1, a2.size(0)) * torch.ones(q1_q2_mul.size()).to(args.device)\n",
    "\n",
    "\t\tq_y = z3 + m * ( (n * z1 * z2) - (z1 * a2) - (z2 * a1) + q1_q2_mul)\n",
    "\t\n",
    "\treturn dict(zip(['qTensor', 'scale', 'zero_point'], [q_y.round().t(), yDict['scale'], yDict['zero_point']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96df07b7-4521-4486-b572-d7fcd3d3e88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantForward(model, x, args):\n",
    "\tflp_act0 = model.flatten(x)\n",
    "\tflp_act1 = model.relu1(model.fc1(flp_act0))\n",
    "\tflp_act2 = model.relu2(model.fc2(flp_act1))\n",
    "\tflp_act3 = model.fc3(flp_act2)\n",
    "\t# Input\t\n",
    "\tqDict0 = quantizeTensor(flp_act0, None, None, args)\n",
    "\tflp_act0 = dequantizeTensor(qDict0, args)\n",
    "\t# 1st FC Layer\n",
    "\tqDict1 = quantizeLayerForward(model.fc1, flp_act0, args)\n",
    "\tflp_act1 = model.relu1(dequantizeTensor(qDict1, args) + model.fc1.bias)\n",
    "\n",
    "\tqDict2 = quantizeLayerForward(model.fc2, flp_act1, args)\n",
    "\tflp_act2 = model.relu2(dequantizeTensor(qDict2, args) + model.fc2.bias)\n",
    "\n",
    "\tqDict3 = quantizeLayerForward(model.fc3, flp_act2, args)\n",
    "\treturn model, qDict1, qDict2, qDict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1b4260a-94ca-433e-baeb-8771d4c25e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQuant(model, test_loader, stats,  args):\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tloss_func = genLossFunc(args)\n",
    "\t\tloss, correct = 0, 0\n",
    "\t\tfor batch_index, (image, label) in enumerate(test_loader):\n",
    "\t\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\t\to_model, qDict1, qDict2, qDict3  = quantForward(model, image, args)\n",
    "\t\t\ty = dequantizeTensor(qDict3, args) + model.fc3.bias.data\n",
    "\t\t\tloss += loss_func(y, label).item()#*image.size(0)\n",
    "\t\t\tcorrect += (y.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tcorrect_rate = 100 * correct / len(test_loader.dataset)\n",
    "\tprint(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%) Loss: {loss/len(test_loader.dataset):.4f}')\n",
    "\treturn o_model, qDict1, qDict2, qDict3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "498de391-09d6-41a3-912f-620906b9d42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9602/10000 (96.0%) Loss: 0.0022\n"
     ]
    }
   ],
   "source": [
    "o_model, q_Dict1, q_Dict2, q_Dict3 = testQuant(q_model, test_loader, old_stats, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195dc18c-340c-4394-870e-9780663da124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
