{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c688ae26-bef9-4988-9133-0346dc4eff32",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5075e9a-43ff-49f5-888b-342d5ecda78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm import tqdm_notebook as tq\n",
    "import tqdm\n",
    "import os, time, math, copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from collections import namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.set_printoptions(precision=8, linewidth=50000)\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff365a5-2a3c-4c10-96db-c2d798de3517",
   "metadata": {},
   "source": [
    "# Print Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8afcf2b-07ca-4b03-93e7-89634b8b20e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLACK\t= '\\033[30m'\n",
    "RED\t\t= '\\033[31m'\n",
    "GREEN\t= '\\033[32m'\n",
    "YELLOW\t= '\\033[33m'\n",
    "BLUE\t= '\\033[34m'\n",
    "MAGENTA\t= '\\033[35m'\n",
    "CYAN\t= '\\033[36m'\n",
    "RESET\t= '\\033[0m'\n",
    "SEL\t\t= '\\033[7m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d6f449a-b38f-449a-abfc-dbdfffd65a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class\tfxp:\n",
    "\tdef\t__init__(self, bIn, iBWF):\n",
    "\t\tself.iFullBW\t= len(bIn)\n",
    "\t\tself.iIntgBW\t= self.iFullBW - iBWF\n",
    "\t\tself.bSign\t\t= bIn[0]\n",
    "\t\tself.bIntg\t\t= bIn[:self.iIntgBW]\n",
    "\t\tself.bFrac\t\t= bIn[self.iIntgBW:]\n",
    "\t\tself.fFull\t\t= 0\n",
    "\t\ttry:\n",
    "\t\t\tfor idx, bit in enumerate(bIn):\n",
    "\t\t\t\tif\tidx == 0:\n",
    "\t\t\t\t\tself.fFull = self.fFull + int(bit,2) * -pow(2, self.iIntgBW - 1)\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tself.fFull = self.fFull + int(bit,2) * pow(2, self.iIntgBW - 1 - idx)\n",
    "\t\texcept:\n",
    "\t\t\tprint(bIn)\n",
    "\t\tself.dispFull\t= RED + self.bIntg + BLUE + self.bFrac + RESET\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "610b93d9-8619-4bcc-b29d-9a3d35104bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class\tflp2fix:\n",
    "\tdef\t__init__(self, fIn, iBW, iBWF):\n",
    "\t\tself.fMin\t\t= fxp('1' + (iBW-1)*'0', iBWF).fFull\n",
    "\t\tself.fMax\t\t= fxp('0' + (iBW-1)*'1', iBWF).fFull\n",
    "\t\tself.fResol\t\t= 2 ** -iBWF\n",
    "\t\tif fIn < self.fMin or fIn > self.fMax:\n",
    "\t\t\tprint('Out of input range during flp -> fix converting ')\n",
    "\t\t\n",
    "\t\tself.iBW\t\t= iBW\n",
    "\t\tself.iBWI\t\t= iBW - iBWF\n",
    "\t\tself.iBWF\t\t= iBWF\n",
    "\n",
    "\t\tself.iFLP2INT\t= abs(int(fIn * 2 ** iBWF))\n",
    "\t\tif fIn < 0:\n",
    "\t\t\tself.iFLP2INT = 2 ** (iBW-1) - self.iFLP2INT\n",
    "\n",
    "\t\tif fIn >= 0:\n",
    "\t\t\tself.bFull = bin(self.iFLP2INT)[2:].rjust(iBW, '0')\n",
    "\t\telse:\n",
    "\t\t\tself.bFull = '1'+bin(self.iFLP2INT)[2:].rjust(iBW-1, '0')\n",
    "\t\t\tif len(self.bFull) > iBW:\n",
    "\t\t\t\tself.bFull = '0' * iBW\n",
    "\n",
    "\t\tself.cssFxp\t\t= fxp(self.bFull, self.iBWF)\n",
    "\t\tself.bSign\t\t= self.cssFxp.bSign\n",
    "\t\tself.bIntg\t\t= self.cssFxp.bIntg\n",
    "\t\tself.bFrac\t\t= self.cssFxp.bFrac\n",
    "\t\tself.fFull\t\t= self.cssFxp.fFull\n",
    "\t\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9144a49-1e87-499f-b90b-715852f489e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, '00000000', 128, 0.0625)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = flp2fix(-0.00006, 8, 4)\n",
    "a.fFull, a.bFull, a.iFLP2INT, a.fResol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b68ddb-8ef2-42a1-94c1-4f708b4907d7",
   "metadata": {},
   "source": [
    "# User Define Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "470d6312-f557-4f84-899f-95686b41e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '~/dataset'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002c0a67-1a39-4ce3-913b-749c11f6878b",
   "metadata": {},
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa129a9b-9a85-4de6-b42a-f8cbfc31231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='PyTorch for MNIST dataset')\n",
    "parser.add_argument('--device', type=str, default='cpu', help='Device')\n",
    "parser.add_argument('--shuffle', action='store_true', default=False, help='enables data shuffle')\n",
    "parser.add_argument('--dataset', type=str, default='mnist', help='training dataset')\n",
    "parser.add_argument('--data_path', type=str, default=data_path, help='path to MNIST')\n",
    "parser.add_argument('--batch_size', type=int, default=64, help='batch size')\n",
    "parser.add_argument('--epochs', type=int, default=2, help='number of epochs to train')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='learning rate')\n",
    "parser.add_argument('--optimizer', type=str, default='adam', help='optimizer')\n",
    "parser.add_argument('--loss_func', type=str, default='cel', help='optimizer')\n",
    "parser.add_argument('--quant_opt', type=str, default='asym', help='Type of Quantization')\n",
    "parser.add_argument('--num_bits', type=int, default=8, help='Number of Quantization Bits')\n",
    "parser.add_argument('--act_quant', type=bool, default=False, help='Activation Quantization')\n",
    "parser.add_argument('--disp', type=bool, default=False, help='Display Model Information')\n",
    "\n",
    "args = parser.parse_args(args=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87afa21c-b407-4698-bf0b-85e9dc4c94f1",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c82ac1a-0065-4d3f-a915-a01a91eb47a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if args.device == 'cuda' else {}\n",
    "if args.dataset == 'mnist':\n",
    "\ttrain_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=True,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=transforms.ToTensor()\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)\n",
    "\n",
    "\ttest_loader = torch.utils.data.DataLoader(\n",
    "\t\tdataset=datasets.MNIST(\n",
    "\t\t\troot=args.data_path,\n",
    "\t\t\ttrain=False,\n",
    "\t\t\tdownload=True,\n",
    "\t\t\ttransform=transforms.ToTensor()\n",
    "\t\t),\n",
    "\t\tbatch_size=args.batch_size,\n",
    "\t\tshuffle=args.shuffle,\n",
    "\t\t**kwargs\n",
    "\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625782c6-b278-4485-a8c9-7c6fec5aafdf",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "98354784-1637-4f2c-85b2-6b53f0805bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(MLP, self).__init__()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.fc1 = nn.Linear(28*28, 32)\n",
    "\t\tself.relu1 = nn.ReLU()\n",
    "\t\tself.fc2 = nn.Linear(32, 16)\n",
    "\t\tself.relu2 = nn.ReLU()\n",
    "\t\tself.fc3 = nn.Linear(16, 10)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.relu1(x)\n",
    "\t\tx = self.fc2(x)\n",
    "\t\tx = self.relu2(x)\n",
    "\t\tlogits = self.fc3(x)\n",
    "\t\treturn logits\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9ebfd9aa-9e7b-4638-8db1-101093cdfb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def genOptimizer(model, args):\n",
    "\tif args.optimizer == 'sgd':\n",
    "\t\toptimizer = torch.optim.SGD(model.parameters(), lr=args.lr)\n",
    "\tif args.optimizer == 'adam':\n",
    "\t\toptimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\treturn optimizer\n",
    "\n",
    "def genLossFunc(args):\n",
    "\tif args.loss_func == 'cel':\n",
    "\t\tloss_func = nn.CrossEntropyLoss()\n",
    "\treturn loss_func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb8fe687-70b1-4f29-8dd4-316acae35dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epoch, args):\n",
    "\tmodel.train()\n",
    "\tloss_func = genLossFunc(args)\n",
    "\toptimizer = genOptimizer(model, args)\n",
    "\tmax_batch_index = int(np.floor(len(train_loader.dataset)/args.batch_size))\n",
    "\trunning_loss = 0\n",
    "\tfor batch_index, (image, label) in enumerate(tq(train_loader, desc='Train', leave=False)):\n",
    "\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\tpred = model(image)\n",
    "\t\tloss = loss_func(pred, label)\n",
    "\t\trunning_loss += loss.item()#*image.size(0)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\t\t\n",
    "\tprint(f'Epoch {epoch+1:<3d}: Avg. Loss: {running_loss/len(train_loader.dataset):.4f}', end = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29189102-050a-463a-bbb8-18ca4ab3700b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_loader, model, epoch, args):\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tloss_func = genLossFunc(args)\n",
    "\t\tloss, correct = 0, 0\n",
    "# \t\tfor batch_index, (image, label) in enumerate(tq(test_loader, desc='Test', leave=False)):\n",
    "\t\tfor batch_index, (image, label) in enumerate(test_loader):\n",
    "\t\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\t\tpred = model(image)\n",
    "\t\t\tloss += loss_func(pred, label).item()#*image.size(0)\n",
    "\t\t\tcorrect += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tloss /= len(test_loader.dataset)\n",
    "\tcorrect_rate = 100 * correct / len(test_loader.dataset)\n",
    "\tprint(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a37298e4-2310-43d0-8990-500051f14cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  : Avg. Loss: 0.0081\tAccuracy: 9115/10000 (91.2%)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train:   0%|          | 0/938 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2  : Avg. Loss: 0.0042\tAccuracy: 9246/10000 (92.5%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def main(model):\n",
    "\tfor epoch in range(args.epochs):\n",
    "\t\ttrain(train_loader, model, epoch, args)\n",
    "\t\ttest(test_loader, model, epoch, args)\n",
    "\tprint(\"Done!\")\n",
    "\treturn model\n",
    "\n",
    "model = main(MLP().to(args.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d81cc72-2c6c-46fb-8c9d-0bea4c6869c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model2fix(model, full_width=8, frac_width=6):\n",
    "\tfor name, _ in model.named_parameters():\n",
    "\t\tif 'weight' in name:\n",
    "\t\t\tfor row, rowVal in enumerate(eval(f'model.{name}.data')):\n",
    "\t\t\t\tfor col, colVal in enumerate(rowVal):\n",
    "\t\t\t\t\texec(f'model.{name}.data[{row}][{col}] = torch.tensor(flp2fix({colVal}, {full_width}, {frac_width}).fFull)')\n",
    "\t\tif 'bias' in name:\n",
    "\t\t\tfor col, colVal in enumerate(eval(f'model.{name}.data')):\n",
    "\t\t\t\texec(f'model.{name}.data[{col}] = torch.tensor(flp2fix({colVal}, {full_width}, {frac_width}).fFull)')\n",
    "\treturn model\n",
    "\n",
    "def in2fix(images, full_width=8, frac_width=6):\n",
    "\tdim_images = images.size()\n",
    "\timages = images.view(-1)\n",
    "\tfor idx_image, image in enumerate(images):\n",
    "\t\ttemp_css = flp2fix(image, full_width, frac_width)\n",
    "\t\timages[idx_image] = torch.tensor(temp_css.fFull)\n",
    "\t\tdel temp_css\n",
    "\treturn images.view(dim_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebfd12bd-736c-4f63-af51-25495477c998",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantFixForward(model, x, args, full_width=8, frac_width=6):\n",
    "\tcmodel = copy.deepcopy(model).to(args.device)\n",
    "\tx = cmodel.flatten(x)\n",
    "\tact0 = in2fix(x, full_width, frac_width)\n",
    "\tact1 = cmodel.relu1(cmodel.fc1(act0))\n",
    "\tact1 = in2fix(act1, full_width, frac_width)\n",
    "\n",
    "\tact2 = cmodel.relu2(cmodel.fc2(act1))\n",
    "\tact2 = in2fix(act2, full_width, frac_width)\n",
    "\tact3 = cmodel.fc3(act2)\n",
    "\tact3 = in2fix(act3, full_width, frac_width)\t\n",
    "\treturn cmodel, act0, act1, act2, act3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3d35ae3-970e-4386-9e03-86690e48af4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQuant(model, test_loader, args):\n",
    "\tfull_width=16\n",
    "\tfrac_width=8\n",
    "\tqmodel = copy.deepcopy(model).to(args.device)\n",
    "\tqmodel = model2fix(qmodel,full_width, frac_width)\n",
    "\tqmodel.eval()\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tloss_func = genLossFunc(args)\n",
    "\t\tloss, correct = 0, 0\n",
    "\t\tfor batch_index, (image, label) in enumerate(test_loader):\n",
    "\t\t\timage, label = image.to(args.device), label.to(args.device)\n",
    "\t\t\tqmodel, act0, act1, act2, act3  = quantFixForward(qmodel, image, args, full_width, frac_width)\n",
    "\t\t\ty = act3\n",
    "\t\t\tloss += loss_func(y, label).item()#*image.size(0)\n",
    "\t\t\tcorrect += (y.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tcorrect_rate = 100 * correct / len(test_loader.dataset)\n",
    "\tprint(f'Accuracy: {correct}/{len(test_loader.dataset)} ({correct_rate:>.1f}%) Loss: {loss/len(test_loader.dataset):.2f}')\n",
    "\treturn qmodel, act0, act1, act2, act3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cab11ff5-8eea-4928-85a9-b92145de83d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 9251/10000 (92.5%) Loss: 0.00\n"
     ]
    }
   ],
   "source": [
    "qmodel, act0, act1, act2, act3 = testQuant(model, test_loader, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3992d273-b6c9-49a8-9951-603cc33e2f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[ 0.00000000,  0.02734375,  0.03125000,  ...,  0.00390625,  0.01562500,  0.00000000],\n",
       "                      [ 0.01562500, -0.02343750,  0.02734375,  ...,  0.01171875,  0.01953125,  0.02343750],\n",
       "                      [-0.01953125,  0.00781250,  0.02734375,  ...,  0.00390625,  0.02343750, -0.01171875],\n",
       "                      ...,\n",
       "                      [ 0.01562500,  0.01171875,  0.01953125,  ...,  0.01562500,  0.00390625, -0.01953125],\n",
       "                      [-0.01171875,  0.00000000, -0.02343750,  ...,  0.00000000, -0.00781250, -0.00390625],\n",
       "                      [-0.03125000, -0.00390625, -0.00390625,  ..., -0.02734375, -0.02734375,  0.00781250]])),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.02734375,  0.18359375, -0.01171875,  0.09765625,  0.07031250,  0.08984375,  0.21093750,  0.22265625,  0.00000000,  0.00000000, -0.04687500, -0.12500000,  0.19140625, -0.03515625,  0.03515625,  0.02734375,  0.03125000, -0.14843750,  0.12109375, -0.03125000,  0.14062500, -0.01953125,  0.23046875, -0.03906250, -0.04296875,  0.21484375, -0.02343750,  0.01562500,  0.14062500,  0.10156250, -0.06640625,  0.18359375])),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.04687500,  0.14062500, -0.16015625, -0.31250000,  0.01562500, -0.14453125, -0.28125000, -0.18359375, -0.08203125, -0.12890625, -0.03515625,  0.11718750,  0.12500000,  0.06640625,  0.23437500,  0.08984375,  0.22265625,  0.27343750,  0.25000000,  0.27343750,  0.16796875, -0.00781250,  0.01953125, -0.03515625,  0.20312500, -0.40625000, -0.11328125, -0.14843750, -0.21093750,  0.23828125,  0.27343750, -0.18359375],\n",
       "                      [-0.12890625,  0.24609375, -0.17578125, -0.27734375,  0.23046875,  0.21484375,  0.24218750,  0.24609375, -0.00390625,  0.16796875, -0.08593750, -0.23437500,  0.07421875,  0.12890625, -0.20312500,  0.25390625, -0.15234375,  0.12109375, -0.09375000,  0.08203125,  0.25000000, -0.20312500,  0.26562500,  0.01171875, -0.09375000,  0.00781250, -0.14453125, -0.10546875,  0.00000000,  0.00000000, -0.06640625,  0.25000000],\n",
       "                      [ 0.25781250,  0.28515625,  0.04296875,  0.30859375,  0.32421875,  0.02734375,  0.10156250,  0.33984375, -0.08984375,  0.08593750,  0.34765625, -0.12109375,  0.07812500,  0.30859375,  0.17187500,  0.21875000, -0.03906250,  0.26953125, -0.18750000, -0.26953125, -0.16796875, -0.14843750, -0.07421875, -0.08984375,  0.06250000, -0.02343750,  0.03515625, -0.13281250, -0.01953125,  0.11328125, -0.21875000,  0.24218750],\n",
       "                      [ 0.15234375,  0.18750000,  0.34765625,  0.10156250,  0.25000000, -0.03515625, -0.23046875, -0.13281250,  0.14843750,  0.06250000, -0.20703125,  0.01171875, -0.00390625,  0.15234375, -0.45312500,  0.00781250, -0.29296875,  0.05468750,  0.14062500,  0.31250000, -0.12890625,  0.16796875, -0.24609375,  0.18750000,  0.18359375,  0.00390625,  0.00390625, -0.24218750, -0.07031250, -0.03515625, -0.24218750,  0.03125000],\n",
       "                      [-0.03515625,  0.27343750, -0.14453125,  0.28125000, -0.00781250,  0.04687500,  0.39843750, -0.25390625,  0.06640625,  0.05859375,  0.00781250, -0.20312500,  0.12500000,  0.11718750,  0.26562500, -0.04687500,  0.23437500, -0.25781250,  0.32421875,  0.23046875,  0.00781250,  0.16796875, -0.20312500,  0.02734375, -0.14453125,  0.05859375, -0.12500000, -0.13281250,  0.33593750,  0.21484375,  0.36718750,  0.12109375],\n",
       "                      [ 0.26953125,  0.30078125,  0.24609375,  0.30859375, -0.26562500, -0.14453125,  0.46484375, -0.25000000, -0.25000000, -0.10156250, -0.14453125, -0.14062500,  0.21484375, -0.03906250, -0.32812500,  0.24609375,  0.04687500, -0.19921875,  0.24218750,  0.00781250,  0.08593750, -0.27734375, -0.04687500, -0.06250000,  0.17187500,  0.03906250, -0.06250000,  0.00390625,  0.07812500, -0.10546875, -0.02734375,  0.05859375],\n",
       "                      [-0.08203125,  0.14062500,  0.19531250, -0.24609375, -0.35546875,  0.33984375,  0.25390625, -0.05859375,  0.05468750,  0.02734375,  0.23437500,  0.09375000,  0.17187500,  0.14062500, -0.21093750,  0.27734375,  0.30468750,  0.14843750, -0.05078125, -0.15625000, -0.02734375,  0.07421875,  0.21093750,  0.01171875,  0.23046875, -0.06640625,  0.00390625,  0.46484375, -0.09765625, -0.27343750,  0.32812500, -0.26953125],\n",
       "                      [ 0.25781250,  0.07031250, -0.06250000,  0.24218750,  0.39843750, -0.16406250, -0.10546875,  0.26171875, -0.18359375, -0.12500000,  0.12109375,  0.21093750,  0.26171875, -0.25390625,  0.32812500, -0.16796875,  0.14062500, -0.08203125, -0.24218750, -0.16796875,  0.28906250,  0.16015625,  0.57812500,  0.19531250, -0.01953125,  0.31640625,  0.08203125, -0.23046875, -0.05468750,  0.07421875, -0.02734375, -0.16796875],\n",
       "                      [-0.12890625, -0.14062500,  0.05078125, -0.16406250, -0.19140625,  0.38281250,  0.04296875,  0.18359375,  0.33203125,  0.00781250, -0.08984375,  0.16015625, -0.02343750,  0.00000000,  0.23437500,  0.11718750,  0.18750000,  0.03906250, -0.11328125,  0.00000000,  0.04296875,  0.31250000, -0.16796875,  0.00000000, -0.04687500,  0.22656250, -0.12500000,  0.21093750,  0.24609375, -0.17968750,  0.14453125,  0.13281250],\n",
       "                      [ 0.30078125, -0.05078125,  0.26171875,  0.07421875, -0.03515625, -0.05859375, -0.46484375,  0.00390625, -0.03515625, -0.12500000,  0.29296875,  0.35937500,  0.25390625,  0.04687500, -0.06640625, -0.25000000,  0.28125000,  0.26562500, -0.27343750,  0.29687500,  0.22265625,  0.06640625,  0.10937500,  0.32812500,  0.15234375,  0.16796875, -0.12890625,  0.23828125, -0.06250000, -0.15625000,  0.27343750, -0.06640625],\n",
       "                      [-0.07031250, -0.09765625, -0.02343750, -0.28906250, -0.17187500,  0.29296875,  0.02734375,  0.10156250,  0.19531250,  0.01562500,  0.18359375,  0.14062500, -0.10156250,  0.08984375,  0.11328125, -0.06640625, -0.16406250,  0.05859375,  0.18750000,  0.26953125,  0.26171875,  0.26953125, -0.15234375, -0.08203125,  0.02734375, -0.19140625, -0.00781250,  0.14843750,  0.30468750,  0.18750000, -0.17187500,  0.32812500],\n",
       "                      [-0.10156250, -0.14453125, -0.15234375, -0.01171875,  0.03515625, -0.17187500,  0.12109375, -0.00781250, -0.14453125, -0.04687500, -0.15625000,  0.00390625, -0.07421875, -0.02343750,  0.06250000,  0.13671875, -0.10156250,  0.14843750, -0.06640625, -0.09375000, -0.14843750, -0.00390625, -0.16796875,  0.10937500,  0.08593750, -0.01953125,  0.08203125,  0.07812500,  0.04296875,  0.12109375, -0.10937500, -0.17187500],\n",
       "                      [ 0.05078125,  0.18359375, -0.13281250, -0.06250000, -0.26171875,  0.15234375, -0.21875000,  0.25390625, -0.16406250, -0.13281250,  0.04296875, -0.03906250,  0.13281250,  0.28515625, -0.09765625,  0.26953125,  0.02734375,  0.17578125,  0.31250000, -0.10546875,  0.06250000, -0.00781250, -0.12890625,  0.05859375,  0.35156250, -0.25781250,  0.02343750,  0.24609375, -0.12109375,  0.35546875, -0.17578125,  0.32812500],\n",
       "                      [-0.10546875,  0.01171875,  0.09765625, -0.07421875, -0.14843750,  0.27734375,  0.25000000,  0.35546875,  0.18750000, -0.10156250, -0.01171875, -0.02734375,  0.16406250, -0.00390625, -0.03515625, -0.08984375,  0.16796875, -0.21875000,  0.18750000,  0.28515625,  0.09765625, -0.05468750,  0.35937500, -0.10546875, -0.08203125,  0.32031250,  0.15625000,  0.26562500,  0.30468750, -0.00781250, -0.26562500,  0.23437500],\n",
       "                      [-0.01171875, -0.16406250, -0.19140625, -0.03515625,  0.30859375, -0.28125000,  0.14062500, -0.17187500,  0.29687500,  0.13281250,  0.10546875, -0.24218750, -0.16015625,  0.28515625, -0.19140625,  0.28906250, -0.40625000,  0.32812500,  0.02343750, -0.08203125,  0.27734375,  0.27343750, -0.37109375,  0.04296875, -0.10937500, -0.26171875, -0.05078125, -0.41015625,  0.25390625, -0.16015625,  0.01953125,  0.10937500],\n",
       "                      [ 0.18359375,  0.09375000,  0.26562500,  0.33984375,  0.39453125,  0.33593750,  0.13281250, -0.14453125,  0.31250000, -0.11718750,  0.17968750,  0.26562500,  0.06250000,  0.01562500,  0.11718750,  0.19140625, -0.30859375, -0.14843750, -0.07421875,  0.19531250, -0.07812500,  0.19921875, -0.22265625,  0.25000000, -0.16796875,  0.41406250, -0.14453125, -0.10937500, -0.05859375, -0.18359375, -0.05859375,  0.09765625]])),\n",
       "             ('fc2.bias',\n",
       "              tensor([-0.08984375,  0.30859375,  0.05859375, -0.12890625,  0.12500000, -0.08593750, -0.05078125,  0.21093750,  0.16796875, -0.17968750,  0.14453125, -0.14062500,  0.02343750,  0.35937500,  0.00390625, -0.01953125])),\n",
       "             ('fc3.weight',\n",
       "              tensor([[ 0.12109375, -0.47265625,  0.11328125, -0.33984375, -0.42187500,  0.01953125,  0.30859375,  0.42968750, -0.59765625,  0.11718750, -0.29296875, -0.08593750,  0.04687500, -0.26562500, -0.26562500, -0.13281250],\n",
       "                      [-0.22656250,  0.10546875, -0.30468750, -0.40625000,  0.20312500, -0.43359375, -0.01171875,  0.00781250,  0.33593750, -0.33984375,  0.33203125,  0.02734375, -0.34375000,  0.19140625,  0.38671875,  0.15625000],\n",
       "                      [ 0.20703125, -0.01171875, -0.50390625,  0.10156250,  0.24609375,  0.16796875,  0.28515625,  0.00000000,  0.10156250,  0.10937500, -0.14062500, -0.03906250, -0.42968750,  0.03906250, -0.33203125,  0.18359375],\n",
       "                      [-0.08593750, -0.25000000,  0.05468750, -0.12890625, -0.25781250, -0.20312500,  0.34765625, -0.39843750,  0.34765625,  0.00000000,  0.19531250, -0.16015625,  0.23828125, -0.01171875, -0.29296875,  0.24218750],\n",
       "                      [-0.57031250, -0.04296875,  0.28515625,  0.25000000,  0.00000000,  0.40234375, -0.26171875, -0.18359375, -0.13281250, -0.37109375, -0.05078125, -0.00781250,  0.07031250,  0.07421875, -0.05859375,  0.17578125],\n",
       "                      [-0.21484375,  0.45703125,  0.08984375,  0.15234375, -0.45312500, -0.39062500, -0.04296875,  0.22656250,  0.05078125,  0.03906250,  0.01953125, -0.02343750, -0.10546875,  0.17187500, -0.22265625,  0.24609375],\n",
       "                      [-0.08984375, -0.59765625,  0.19921875, -0.41406250,  0.40234375, -0.29687500, -0.33203125,  0.38671875, -0.38671875, -0.05468750, -0.30078125, -0.01953125, -0.28125000, -0.25390625, -0.12890625,  0.20312500],\n",
       "                      [ 0.33203125,  0.12890625, -0.07031250, -0.24218750,  0.24609375,  0.01562500, -0.10546875, -0.13671875, -0.14453125, -0.17578125,  0.22265625, -0.18750000,  0.38281250,  0.30468750, -0.41406250, -0.53906250],\n",
       "                      [ 0.21093750, -0.37500000, -0.05078125,  0.35937500, -0.16796875, -0.19140625, -0.18750000, -0.16015625, -0.12109375,  0.19140625,  0.16406250, -0.23437500,  0.00000000, -0.42968750,  0.28906250,  0.22656250],\n",
       "                      [ 0.26562500,  0.24218750,  0.17968750,  0.03125000,  0.08203125,  0.20312500,  0.23046875, -0.31250000, -0.26562500, -0.22265625, -0.20312500, -0.23828125,  0.08984375, -0.48437500,  0.33203125, -0.12890625]])),\n",
       "             ('fc3.bias',\n",
       "              tensor([-0.03125000,  0.30859375,  0.01953125,  0.03125000, -0.13281250,  0.35156250,  0.01562500, -0.13671875, -0.20703125,  0.03906250]))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmodel.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b718f0-bb86-49af-8f3e-adb23b3d848a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
