{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "583fd3a6-b9a0-44d6-b3bc-4699bef35c5e",
   "metadata": {},
   "source": [
    "# MNIST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d5345d-ac54-4845-9be1-bff83185cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a34062-b6ae-4e07-bbed-658d7c05525d",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b725318-c76b-45da-a04f-e2ebac8b9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '~/dataset'\n",
    "train_data = datasets.MNIST(root=dataset_dir, train=True,  download=True, transform=ToTensor())\n",
    "test_data  = datasets.MNIST(root=dataset_dir, train=False, download=True, transform=ToTensor())\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Number of trainData/validData/testData = 50000/10000/10000\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader  = DataLoader(test_data,  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdddba9e-3d46-49bd-8d02-e82b4b81999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise(x, axs):\n",
    "\tx = x.view(-1).cpu().numpy()\n",
    "\taxs.hist(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966d9254-d9cf-4f28-b95d-92fa7df16fc7",
   "metadata": {},
   "source": [
    "# MNIST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fccd9bff-19b3-45df-a200-20ca50454eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "class NN(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(NN, self).__init__()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.fc1 = nn.Linear(28*28, 16)\n",
    "\t\tself.fc2 = nn.Linear(16, 16)\n",
    "\t\tself.fc3 = nn.Linear(16, 10)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\tx = F.relu(self.fc2(x))\n",
    "\t\tlogits = self.fc3(x)\n",
    "\n",
    "\t\treturn logits\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b664c-17c4-4d34-ba3b-93497aa44698",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80be6dd-b33a-4fb5-85d0-c32218d8d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, loss_func, optimizer, epoch):\n",
    "\tmodel.train()\n",
    "\tmax_batch_index = int(np.floor(len(train_data)/batch_size))\n",
    "\tfor batch_index, (image, label) in enumerate(train_dataloader):\n",
    "\t\timage, label = image.to(device), label.to(device)\n",
    "\t\tpred = model(image)\n",
    "\t\tloss = loss_func(pred, label)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\t\t\n",
    "\t\tif batch_index == max_batch_index:\n",
    "\t\t\tprint(f'Epoch {epoch+1:<3d}: Loss: {loss.item():.2f}', end = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079efc4f-7722-431f-86d4-c63b94bcebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_dataloader, model, loss_func, epoch):\n",
    "\tmodel.eval()\n",
    "\tloss, correct = 0, 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor image, label in test_dataloader:\n",
    "\t\t\timage, label = image.to(device), label.to(device)\n",
    "\t\t\tpred = model(image)\n",
    "\t\t\tloss += loss_func(pred, label).item()\n",
    "\t\t\tcorrect += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tloss /= len(test_dataloader.dataset)\n",
    "\tcorrect_rate = 100 * correct / len(test_dataloader.dataset)\n",
    "\tprint(f'Accuracy: {correct}/{len(test_data)} ({correct_rate:>.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae6c6141-94fe-4ee6-ad1e-4a59fe1db8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\tmodel = NN().to(device)\n",
    "\toptimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\tepochs = 10\n",
    "\tfor epoch in range(epochs):\n",
    "\t\ttrain(train_dataloader, model, loss_func, optimizer, epoch)\n",
    "\t\ttest(test_dataloader, model, loss_func, epoch)\n",
    "\tprint(\"Done!\")\n",
    "\treturn model\n",
    "\n",
    "# model = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01350b1-661b-44f3-bd40-9d6f2eb91552",
   "metadata": {},
   "source": [
    "# Quantization of Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b732b0-6fd7-4714-aa25-c79dfbba54b7",
   "metadata": {},
   "source": [
    "## Quantization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40788c28-5892-4c83-b4cd-85fe48720d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcScaleZeroPoint(min_val, max_val, num_bits=8, opt='asym'):\n",
    "\tqmin, qmax = 0., 2.**num_bits - 1.\n",
    "\tif opt == 'asym':\n",
    "\t\tscale = (max_val - min_val) / (qmax - qmin)\n",
    "\t\tinitial_zero_point = -min_val / scale\n",
    "\t\tzero_point = int({initial_zero_point < qmin: qmin,  initial_zero_point > qmax: qmax, qmin <= initial_zero_point <= qmax: initial_zero_point}.get(True, False))\n",
    "\tif opt == 'sym':\n",
    "\t\tscale = max(abs(min_val), abs(max_val)) / qmax\n",
    "\t\tzero_point = 0\n",
    "\treturn scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a8f4aa-1f98-4f3b-a11a-bbec3ca99868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizeTensor(input_tensor, min_val=None, max_val=None, num_bits=8, opt='asym'):\n",
    "\tif not min_val and not max_val:\n",
    "\t\tmin_val, max_val = input_tensor.min(), input_tensor.max()\n",
    "\t\n",
    "\tqmin, qmax = 0., 2.**num_bits - 1.\n",
    "\tscale, zero_point = calcScaleZeroPoint(min_val, max_val, num_bits, opt)\n",
    "\t\n",
    "\tif opt == 'asym':\n",
    "\t\tquant_tensor = (input_tensor / scale + zero_point).clamp(qmin, qmax).round()\n",
    "\tif opt == 'sym':\n",
    "\t\tquant_tensor = (input_tensor / scale).clamp(qmax, qmax).round()\n",
    "\t\n",
    "\tqTuple = namedtuple('qTuple', ['tensor', 'scale', 'zero_point'])\n",
    "\treturn qTuple(tensor=quant_tensor, scale=scale, zero_point=zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "551f3c25-e727-4434-a601-f68e6e0cafba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantizeTensor(qTuple, opt='asym'):\n",
    "\tif opt == 'asym':\n",
    "\t\tdequant_tensor = qTuple.scale * (qTuple.tensor.float() - qTuple.zero_point)\n",
    "\tif opt == 'sym':\n",
    "\t\tdequant_tensor = qTuple.scale * (qTuple.tensor.float())\t\n",
    "\treturn dequant_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b7e09c-4523-44da-bad9-44f53c86f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateStats(actTensor, stats, layerName):\n",
    "\t# dim=0 : find min/max in each col\n",
    "\t# dim=1 : find min/max in each row\n",
    "\tmaxValue = torch.max(actTensor, dim=1)[0]\n",
    "\tminValue = torch.min(actTensor, dim=1)[0]\n",
    "\t\n",
    "\tif layerName not in stats:\n",
    "\t\tstats[layerName] = {'max': maxValue.sum(), 'min': minValue.sum(), 'total': 1}\n",
    "\telse:\n",
    "\t\tstats[layerName]['max'] += maxValue.sum().item()\n",
    "\t\tstats[layerName]['min'] += maxValue.sum().item()\n",
    "\t\tstats[layerName]['total'] += 1\n",
    "\t\t\n",
    "\tweighting = 2.0 / (stats[layerName]['total']) + 1\n",
    "\n",
    "\tif 'ema_min' in stats[layerName]:\n",
    "\t\tstats[layerName]['ema_min'] = weighting*(minValue.mean().item()) + (1 - weighting) * stats[layerName]['ema_min']\n",
    "\telse:\n",
    "\t\tstats[layerName]['ema_min'] = weighting*(minValue.mean().item())\n",
    "\n",
    "\tif 'ema_max' in stats[layerName]:\n",
    "\t\tstats[layerName]['ema_max'] = weighting*(maxValue.mean().item()) + (1 - weighting) * stats[layerName]['ema_max']\n",
    "\telse: \n",
    "\t\tstats[layerName]['ema_max'] = weighting*(maxValue.mean().item())\n",
    "\n",
    "\t\tstats[layerName]['min_val'] = stats[layerName]['min']/ stats[layerName]['total']\n",
    "\t\tstats[layerName]['max_val'] = stats[layerName]['max']/ stats[layerName]['total']\n",
    "\n",
    "\treturn stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af59c4ae-3014-4e64-af00-c92eeb54b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reworked Forward Pass to access activation Stats through updateStats function\n",
    "def gatherActivationStats(model, x, stats):\n",
    "\tx = model.flatten(x)\n",
    "\tstats = updateStats(x, stats, 'fc1')\n",
    "\tx = F.relu(model.fc1(x))\n",
    "\t\n",
    "\tstats = updateStats(x, stats, 'fc2')\n",
    "\tx = F.relu(model.fc2(x))\n",
    "\n",
    "\tstats = updateStats(x, stats, 'fc3')\n",
    "\tx = model.fc3(x)\n",
    "\n",
    "\treturn stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4865518a-d7ca-482d-a6e4-38cb8b9459e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry function to get stats of all functions.\n",
    "def gatherStats(model, testDataLoader):\n",
    "\tmodel.eval()\n",
    "\tstats = {}\n",
    "\twith torch.no_grad():\n",
    "\t\tfor img, lab in testDataLoader:\n",
    "\t\t\timg, lab = img.to(device), lab.to(device)\n",
    "\t\t\tstats = gatherActivationStats(model, img, stats)\n",
    "\n",
    "\tfinal_stats = {}\n",
    "\tfor key, value in stats.items():\n",
    "\t\tfinal_stats[key] = { \"max\" : value[\"max\"] / value[\"total\"], \"min\" : value[\"min\"] / value[\"total\"], \"ema_min\": value[\"ema_min\"], \"ema_max\": value[\"ema_max\"] }\n",
    "\treturn final_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0986c97-c07a-4974-a2a2-7fc7e3eb2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeQuantOp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, min_val=None, max_val=None, num_bits=8, opt='asym'):\n",
    "\t\t#def quantizeTensor(input_tensor, min_val=None, max_val=None, num_bits=4, opt='asym'):\n",
    "        x = quantizeTensor(x, min_val=min_val, max_val=max_val, num_bits=num_bits, opt=opt)\n",
    "        x = dequantizeTensor(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # straight through estimator\n",
    "        return grad_output, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebd77813-e820-4f02-8feb-64bc5cd71b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantAwareTrainingForward(x, model, stats, act_quant=False, num_bits=8, opt='asym'):\n",
    "\tparams = model.state_dict()\n",
    "\t\n",
    "\tx = model.flatten(x)\n",
    "\t\n",
    "\tmodel.fc1.weight.data = FakeQuantOp.apply(model.fc1.weight.data, None, None, num_bits, opt)\n",
    "\tmodel.fc1.bias.data = FakeQuantOp.apply(model.fc1.bias.data, None, None, num_bits, opt)\n",
    "\n",
    "# \tx = F.relu(model.fc1(x))\n",
    "\twith torch.no_grad():\n",
    "\t\tstats = updateStats(x.clone().view(x.shape[0], -1), stats, 'fc1')\n",
    "\tif act_quant:\n",
    "\t\tx = FakeQuantOp.apply(x, stats['fc1']['ema_min'], stats['fc1']['ema_max'], num_bits, opt)\n",
    "\tx = F.relu(model.fc1(x))\n",
    "\t\n",
    "\tmodel.fc2.weight.data = FakeQuantOp.apply(model.fc2.weight.data, None, None, num_bits, opt)\n",
    "\tmodel.fc2.bias.data = FakeQuantOp.apply(model.fc2.bias.data, None, None, num_bits, opt)\n",
    "# \tx = F.relu(model.fc2(x))\n",
    "\twith torch.no_grad():\n",
    "\t\tstats = updateStats(x.clone().view(x.shape[0], -1), stats, 'fc2')\n",
    "\tif act_quant:\n",
    "\t\tx = FakeQuantOp.apply(x, stats['fc2']['ema_min'], stats['fc2']['ema_max'], num_bits, opt)\n",
    "\tx = F.relu(model.fc2(x))\n",
    "\n",
    "\tmodel.fc3.weight.data = FakeQuantOp.apply(model.fc3.weight.data, None, None, num_bits, opt)\n",
    "\tmodel.fc3.bias.data = FakeQuantOp.apply(model.fc3.bias.data, None, None, num_bits, opt)\n",
    "# \tx = model.fc3(x)\n",
    "\twith torch.no_grad():\n",
    "\t\tstats = updateStats(x.clone().view(x.shape[0], -1), stats, 'fc3')\n",
    "\tif act_quant:\n",
    "\t\tx = FakeQuantOp.apply(x, stats['fc3']['ema_min'], stats['fc3']['ema_max'], num_bits, opt)\n",
    "\tx = model.fc3(x)\n",
    "\t\n",
    "#\treturn F.log_softmax(x, dim=1), fc1_weight, fc2_weight, fc3_weight, stats\n",
    "\treturn x, params, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1801eb1c-e0df-473f-971f-8c8943c04f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainQAT(train_dataloader, model, loss_func, optimizer, epoch, stats, act_quant=False, num_bits=8, opt='asym'):\n",
    "\tmodel.train()\n",
    "\tmax_batch_index = int(np.floor(len(train_data)/batch_size))\n",
    "\tfor batch_index, (image, label) in enumerate(train_dataloader):\n",
    "\t\timage, label = image.to(device), label.to(device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\ty = model(image)\n",
    "\t\ty, params, stats = quantAwareTrainingForward(image, model, stats, act_quant, num_bits, opt)\n",
    "\t\t\n",
    "\t\t# Recover FP32 to improve accuracy\n",
    "\t\tmodel.fc1.weight.data = params['fc1.weight']\n",
    "\t\tmodel.fc2.weight.data = params['fc2.weight']\n",
    "\t\tmodel.fc3.weight.data = params['fc3.weight']\n",
    "\t\tmodel.fc1.bias.data   = params['fc1.bias']\n",
    "\t\tmodel.fc2.bias.data   = params['fc2.bias']\n",
    "\t\tmodel.fc3.bias.data   = params['fc3.bias']\n",
    "\n",
    "\t\tloss = loss_func(y, label)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\tif batch_index == max_batch_index:\n",
    "\t\t\tprint(f'Epoch {epoch+1:<3d}: Loss: {loss.item():.2f}', end = '\\t')\n",
    "\t\t\t\n",
    "\treturn stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16fb3bab-b0f9-4515-80fe-bbb156cbc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQAT(test_dataloader, model, epoch, loss_func, stats, act_quant=False, num_bits=8, opt='asym'):\n",
    "\tmodel.eval()\n",
    "\tloss, correct = 0, 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor image, label in test_dataloader:\n",
    "\t\t\timage, label = image.to(device), label.to(device)\n",
    "\t\t\ty, _, _ = quantAwareTrainingForward(image, model, stats, act_quant, num_bits, opt)\t\n",
    "\t\t\tloss += loss_func(y, label).item()\n",
    "\t\t\tcorrect += (y.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tloss /= len(test_dataloader.dataset)\n",
    "\tcorrect_rate = 100 * correct / len(test_dataloader.dataset)\n",
    "\tprint(f'Accuracy: {correct}/{len(test_data)} ({correct_rate:>.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "951d6389-bfeb-4828-8dec-563dc75dbde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainQAT():\n",
    "\tmodel = NN().to(device)\n",
    "\toptimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\tepochs = 10\n",
    "\tnum_bits = 8\n",
    "\tstats = {}\n",
    "\topt = 'asym'\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tact_quant = True if epoch > 5 else False\n",
    "\t\t#def trainQAT(train_dataloader, model, loss_func, optimizer, epoch, stats, act_quant=False, num_bits=8, opt='asym'):\n",
    "\t\tstats = trainQAT(train_dataloader, model, loss_func, optimizer, epoch, stats, act_quant, num_bits, opt)\n",
    "\t\ttestQAT(test_dataloader, model, epoch, loss_func, stats, act_quant, num_bits, opt)\n",
    "\tprint(\"Done!\")\n",
    "\treturn model, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "87681f61-fcf6-4799-985b-5f45d420bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  : Loss: 2.12\tAccuracy: 3212/10000 (32.1%)\n",
      "Epoch 2  : Loss: 1.27\tAccuracy: 6879/10000 (68.8%)\n",
      "Epoch 3  : Loss: 0.62\tAccuracy: 7795/10000 (78.0%)\n",
      "Epoch 4  : Loss: 0.43\tAccuracy: 8287/10000 (82.9%)\n",
      "Epoch 5  : Loss: 0.34\tAccuracy: 8535/10000 (85.3%)\n",
      "Epoch 6  : Loss: 0.29\tAccuracy: 8707/10000 (87.1%)\n",
      "Epoch 7  : Loss: 0.33\tAccuracy: 8308/10000 (83.1%)\n",
      "Epoch 8  : Loss: 0.34\tAccuracy: 8249/10000 (82.5%)\n",
      "Epoch 9  : Loss: 0.31\tAccuracy: 8313/10000 (83.1%)\n",
      "Epoch 10 : Loss: 0.34\tAccuracy: 8180/10000 (81.8%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "q_model, old_stats = mainQAT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aff51b-eec0-4568-ba99-55daa00f9a89",
   "metadata": {},
   "source": [
    "## Rework Forward pass of Linear and Conv Layers to support Quantisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "944b011b-7872-49ed-8277-41448829cc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 8180/10000 (81.8%)\n"
     ]
    }
   ],
   "source": [
    "testQAT(test_dataloader, q_model, epoch=10, loss_func=loss_func, stats=old_stats, act_quant=True, num_bits=8, opt='asym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15ac1184-ea39-4ff6-b612-7de355a959c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0151, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0101, 0.0000, 0.0000,  ..., 0.0226, 0.0327, 0.0151],\n",
       "        [0.0101, 0.0226, 0.0302,  ..., 0.0000, 0.0000, 0.0327],\n",
       "        ...,\n",
       "        [0.0000, 0.0327, 0.0000,  ..., 0.0101, 0.0226, 0.0226],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0025],\n",
       "        [0.0000, 0.0000, 0.0327,  ..., 0.0000, 0.0151, 0.0126]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = q_model.state_dict()['fc1.weight']\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c625529d-2395-455e-99f0-08e96b542412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qTuple(tensor=tensor([[ 0.,  6.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 4.,  0.,  0.,  ...,  9., 13.,  6.],\n",
       "        [ 4.,  9., 12.,  ...,  0.,  0., 13.],\n",
       "        ...,\n",
       "        [ 0., 13.,  0.,  ...,  4.,  9.,  9.],\n",
       "        [ 0.,  0.,  0.,  ...,  0.,  0.,  1.],\n",
       "        [ 0.,  0., 13.,  ...,  0.,  6.,  5.]], device='cuda:0'), scale=tensor(0.0025, device='cuda:0'), zero_point=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = quantizeTensor(weight)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67e6b3d8-d10b-4604-b537-c3ae1015609e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0151, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0101, 0.0000, 0.0000,  ..., 0.0226, 0.0327, 0.0151],\n",
       "        [0.0101, 0.0226, 0.0302,  ..., 0.0000, 0.0000, 0.0327],\n",
       "        ...,\n",
       "        [0.0000, 0.0327, 0.0000,  ..., 0.0101, 0.0226, 0.0226],\n",
       "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0025],\n",
       "        [0.0000, 0.0000, 0.0327,  ..., 0.0000, 0.0151, 0.0126]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantizeTensor(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35fcaa9a-207f-4578-9899-b8745615549a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[0.0000, 0.0000, 0.0000,  ..., 0.0241, 0.0000, 0.0000],\n",
       "                      [0.0000, 0.0000, 0.0199,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                      [0.0167, 0.0053, 0.0248,  ..., 0.0000, 0.0112, 0.0175],\n",
       "                      ...,\n",
       "                      [0.0329, 0.0000, 0.0109,  ..., 0.0173, 0.0000, 0.0162],\n",
       "                      [0.0111, 0.0211, 0.0000,  ..., 0.0000, 0.0000, 0.0220],\n",
       "                      [0.0000, 0.0185, 0.0000,  ..., 0.0239, 0.0000, 0.0220]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([0.0000, 0.0010, 0.0000, 0.0003, 0.0000, 0.0011, 0.0000, 0.0011, 0.0002,\n",
       "                      0.0005, 0.0011, 0.0005, 0.0013, 0.0004, 0.0005, 0.0014],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[3.1006e-03, 3.6836e-03, 3.4716e-03, 8.1622e-03, 6.6252e-03, 3.1801e-03,\n",
       "                       2.3776e-01, 1.6775e-02, 4.3461e-03, 3.6041e-03, 1.3656e+00, 1.9345e-03,\n",
       "                       4.8496e-03, 3.2331e-03, 5.3163e-01, 2.5706e-03],\n",
       "                      [2.8091e-03, 4.1527e-02, 1.2985e-03, 5.4901e-01, 1.2190e-03, 2.8790e-01,\n",
       "                       1.2455e-03, 1.3250e-03, 7.4477e-01, 9.1878e-02, 7.1552e-04, 1.5442e-01,\n",
       "                       7.9502e-04, 4.5051e-04, 7.9502e-04, 9.5402e-04],\n",
       "                      [2.0342e-01, 6.6853e-01, 0.0000e+00, 5.0086e-03, 7.4202e-04, 6.8902e-04,\n",
       "                       2.5973e-01, 1.0865e-03, 7.9502e-04, 8.7452e-04, 3.7101e-04, 0.0000e+00,\n",
       "                       9.1843e-01, 2.8594e-01, 8.0827e-03, 0.0000e+00],\n",
       "                      [7.4202e-04, 8.7452e-04, 2.1378e-01, 2.9681e-03, 1.9875e-03, 1.0865e-03,\n",
       "                       1.2455e-03, 2.7985e-02, 1.2985e-03, 8.2523e-02, 1.1288e+00, 4.5051e-03,\n",
       "                       1.1925e-03, 9.0102e-04, 2.7863e-01, 4.7092e-02],\n",
       "                      [1.6324e-02, 9.8052e-04, 1.3250e-04, 9.2842e-01, 3.9751e-04, 3.1279e-01,\n",
       "                       4.6111e-03, 3.9751e-04, 3.9446e-01, 2.6501e-04, 9.5402e-04, 5.3001e-05,\n",
       "                       2.4911e-03, 1.2190e-03, 2.4063e-02, 1.0600e-04],\n",
       "                      [7.9245e-01, 2.6501e-03, 2.8774e-01, 3.8161e-03, 7.6014e-01, 3.4451e-04,\n",
       "                       9.8309e-01, 1.5635e-03, 1.8550e-03, 1.3780e-03, 1.6165e-03, 0.0000e+00,\n",
       "                       1.6695e-03, 9.7194e-01, 6.6106e-01, 5.3001e-05],\n",
       "                      [1.4045e-03, 1.1925e-03, 1.0070e-03, 5.7721e-01, 1.0070e-03, 6.6437e-02,\n",
       "                       4.6906e-03, 1.0070e-03, 6.7850e-01, 3.4451e-04, 2.9257e-01, 6.8902e-04,\n",
       "                       1.5900e-03, 3.9751e-04, 6.3602e-04, 3.4451e-04],\n",
       "                      [4.0612e-01, 1.3515e-03, 1.5994e+00, 2.3851e-04, 4.5115e-01, 2.3294e-02,\n",
       "                       2.0936e-03, 2.9151e-03, 1.7490e-03, 2.6212e-01, 1.3250e-04, 8.6986e-01,\n",
       "                       5.5651e-04, 1.6367e-01, 2.7826e-03, 6.8456e-01],\n",
       "                      [2.5033e-01, 5.6081e-01, 0.0000e+00, 2.6501e-04, 3.9751e-04, 0.0000e+00,\n",
       "                       2.1466e-03, 1.6165e-03, 9.3791e-01, 0.0000e+00, 1.0335e-03, 4.7667e-01,\n",
       "                       8.4993e-01, 9.2752e-04, 3.4451e-04, 0.0000e+00],\n",
       "                      [5.7459e-01, 3.9486e-03, 2.9694e-01, 7.7912e-03, 5.4705e-01, 4.7966e-03,\n",
       "                       5.2471e-01, 3.0892e-01, 5.4061e-03, 2.4805e-02, 6.2542e-03, 4.5687e-02,\n",
       "                       5.5651e-03, 8.5041e-02, 5.9096e-03, 1.3330e-02],\n",
       "                      [4.2401e-04, 1.1395e-03, 9.9486e-01, 3.1801e-03, 1.3780e-03, 1.0335e-03,\n",
       "                       1.7225e-03, 1.7367e+00, 1.4575e-03, 7.4202e-04, 5.8089e-02, 1.2281e+00,\n",
       "                       1.5635e-03, 8.7452e-04, 9.5402e-04, 2.9453e-01],\n",
       "                      [1.3804e-01, 1.4575e-03, 2.9169e-01, 9.3547e-03, 2.7826e-03, 9.7472e-01,\n",
       "                       0.0000e+00, 7.0757e-03, 3.6836e-03, 3.0211e-03, 5.0881e-03, 1.5317e-02,\n",
       "                       2.2526e-03, 3.1430e-01, 1.0739e+00, 6.0122e-01],\n",
       "                      [7.9502e-05, 7.5066e-01, 5.3001e-04, 5.0351e-03, 1.3515e-03, 3.4716e-03,\n",
       "                       1.7490e-03, 2.5441e-03, 1.9875e-03, 1.0614e+00, 1.8762e-02, 0.0000e+00,\n",
       "                       1.2455e-03, 6.9103e-01, 8.4802e-04, 4.5157e-01],\n",
       "                      [2.9681e-03, 2.9946e-03, 8.7982e-03, 3.0865e-01, 7.5792e-03, 6.4301e-01,\n",
       "                       6.2012e-03, 3.2742e-01, 5.8831e-03, 1.7244e-01, 3.1069e-01, 6.2807e-03,\n",
       "                       5.1411e-03, 3.2331e-03, 5.2471e-03, 8.3048e-01],\n",
       "                      [4.4866e-02, 1.2318e-01, 6.5987e-03, 8.4007e-03, 5.5121e-03, 3.4981e-03,\n",
       "                       6.3337e-03, 4.9485e-01, 6.1879e-02, 1.6165e-03, 6.4397e-03, 4.7677e-01,\n",
       "                       7.9923e-01, 8.8459e-02, 4.0281e-03, 2.4646e-03],\n",
       "                      [5.7835e-01, 1.1395e-03, 0.0000e+00, 5.4801e-01, 4.1418e-01, 3.3735e-01,\n",
       "                       9.6878e-01, 8.7452e-04, 1.1660e-03, 6.8902e-04, 1.2190e-03, 0.0000e+00,\n",
       "                       1.9080e-03, 1.4207e-01, 5.1533e-01, 0.0000e+00]], device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([0.1764, 0.1764, 0.0913, 0.1770, 0.0316, 0.0027, 0.1766, 0.0314, 0.1071,\n",
       "                      0.0000, 0.0004, 0.1764, 0.0555, 0.0014, 0.0009, 0.0000],\n",
       "                     device='cuda:0')),\n",
       "             ('fc3.weight',\n",
       "              tensor([[0.0013, 0.2370, 0.4820, 0.0016, 0.4475, 0.2897, 0.0018, 0.5644, 0.0258,\n",
       "                       0.5421, 0.0432, 0.5644, 0.5339, 0.0789, 0.0076, 0.2775],\n",
       "                      [0.5644, 0.0585, 0.0523, 0.5644, 0.3455, 0.2838, 0.4343, 0.3253, 0.2046,\n",
       "                       0.0848, 0.5644, 0.0158, 0.0920, 0.1229, 0.1954, 0.1252],\n",
       "                      [0.0214, 0.2832, 0.0119, 0.3508, 0.0375, 0.2250, 0.1304, 0.5644, 0.2213,\n",
       "                       0.0440, 0.3516, 0.5644, 0.0659, 0.5644, 0.4128, 0.0265],\n",
       "                      [0.3089, 0.2715, 0.0067, 0.3835, 0.5644, 0.3278, 0.3121, 0.0149, 0.0080,\n",
       "                       0.0076, 0.3797, 0.4280, 0.5644, 0.5644, 0.0076, 0.4111],\n",
       "                      [0.0135, 0.1154, 0.5644, 0.0070, 0.0805, 0.5086, 0.1234, 0.0530, 0.5644,\n",
       "                       0.0090, 0.5412, 0.0064, 0.4454, 0.0067, 0.5644, 0.2870],\n",
       "                      [0.5483, 0.0116, 0.5644, 0.1977, 0.0188, 0.5644, 0.0130, 0.1384, 0.0196,\n",
       "                       0.2736, 0.2919, 0.5644, 0.4388, 0.0084, 0.0020, 0.4415],\n",
       "                      [0.1924, 0.0079, 0.3047, 0.3002, 0.0018, 0.1902, 0.0017, 0.5644, 0.3918,\n",
       "                       0.5644, 0.3809, 0.0190, 0.5644, 0.0581, 0.4139, 0.0329],\n",
       "                      [0.0902, 0.5644, 0.0016, 0.0371, 0.5644, 0.0115, 0.5644, 0.3245, 0.5644,\n",
       "                       0.3701, 0.0554, 0.0713, 0.0026, 0.0009, 0.0011, 0.5392],\n",
       "                      [0.5644, 0.0290, 0.2233, 0.2659, 0.2095, 0.3225, 0.1879, 0.2000, 0.1119,\n",
       "                       0.5644, 0.3554, 0.2951, 0.0264, 0.4167, 0.4223, 0.3923],\n",
       "                      [0.1507, 0.4418, 0.5644, 0.0406, 0.5644, 0.2969, 0.5644, 0.0162, 0.5644,\n",
       "                       0.0107, 0.3227, 0.0864, 0.0100, 0.2439, 0.3861, 0.4551]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc3.bias',\n",
       "              tensor([0.0000, 0.0007, 0.0013, 0.0009, 0.0010, 0.0010, 0.0002, 0.0001, 0.0012,\n",
       "                      0.0011], device='cuda:0'))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75517c42-e301-488b-9b28-098823b53667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizeLayer(qActTuple, layer, stat, numBits=4, opt='asym'):\n",
    "\tW, B = layer.weight.data, layer.bias.data\n",
    "\t\n",
    "\tqWeightTuple = quantizeTensor(W, numBits=numBits, opt=opt)\n",
    "\tqBiasTuple   = quantizeTensor(B, numBits=numBits, opt=opt)\n",
    "\t\n",
    "\tlayer.weight.data = qWeightTuple.qTensor.float()\n",
    "\tlayer.bias.data   = qBiasTuple.qTensor.float()\n",
    "\t\n",
    "\tnextScale, nextZeroPoint = calcScaleZeroPoint(minValue=stat['min'], maxValue=stat['max'], numBits=numBits, opt=opt)\n",
    "\t\n",
    "\tweightScale = qWeightTuple.scale\n",
    "\tweightZeroPoint = qWeightTuple.zeroPoint\n",
    "\t\n",
    "\tif opt == 'asym':\n",
    "\t\tlayer.weight.data = ((qWeightTuple.scale * qActTuple.scale) / nextScale) * (layer.weight.data - qWeightTuple.zeroPoint)\n",
    "\t\tlayer.bias.data = (qBiasTuple.scale / nextScale) * (layer.bias.data - qBiasTuple.zeroPoint)\t\t\n",
    "\t\toAct = layer(qActTuple.qTensor.float() - qActTuple.zeroPoint) + nextZeroPoint\n",
    "\tif opt == 'sym':\n",
    "\t\tlayer.weight.data = ((qWeightTuple.scale * qActTuple.scale) / nextScale) * (layer.weight.data)\n",
    "\t\tlayer.bias.data = (qBiasTuple.scale / nextScale) * (layer.bias.data)\n",
    "\t\toAct = layer(qActTuple.qTensor.float())\n",
    "\t\t\n",
    "\tlayer.weight.data, layer.bias.data = W, B\n",
    "\t\n",
    "\treturn oAct.round(), nextScale, nextZeroPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96b34509-aadf-4e11-9c60-7495f367f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantForward(x, model, stats, num_bits=8, opt='asym'):\n",
    "\t# Quantise before inputting into incoming layers\n",
    "\tx = quantizeTensor()\n",
    "\tif sym:\n",
    "\t\tx = quantize_tensor_sym(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'], num_bits=num_bits)\n",
    "\telse:\n",
    "\t\tx = quantize_tensor(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'], num_bits=num_bits)\n",
    "\n",
    "\tx, scale_next, zero_point_next = quantizeLayer(x.tensor, model.conv1, stats['conv2'], x.scale, x.zero_point, vis, axs, X=X, y=y+1, sym=sym, num_bits=num_bits)\n",
    "\n",
    "\tx = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "\n",
    "\n",
    "\tx, scale_next, zero_point_next = quantizeLayer(x, model.conv2, stats['fc1'], scale_next, zero_point_next, vis, axs, X=X, y=y+3, sym=sym, num_bits=num_bits)\n",
    "\n",
    "\tx = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "\n",
    "\tx = x.view(-1, 4*4*50)\n",
    "\n",
    "\tx, scale_next, zero_point_next = quantizeLayer(x, model.fc1, stats['fc2'], scale_next, zero_point_next, vis, axs, X=X+1, y=0, sym=sym, num_bits=num_bits)\n",
    "\n",
    "\n",
    "\t# Back to dequant for final layer\n",
    "# \tif sym:\n",
    "# \t\tx = dequantize_tensor_sym(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "# \telse:\n",
    "# \t\tx = dequantize_tensor(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "\n",
    "\n",
    "\tx = model.fc2(x)\n",
    "\n",
    "\tif vis:\n",
    "\t\taxs[X+1,3].set_xlabel('Unquantised Weights of fc2 layer')\n",
    "\t\tvisualise(model.fc2.weight.data,axs[X+1,3])\n",
    "\n",
    "\t\taxs[X+1,2].set_xlabel('Output after fc2 but dequantised visualised below: ')\n",
    "\t\tvisualise(x,axs[X+1,4])\n",
    "\n",
    "\treturn F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5c8ae37e-fa48-4b07-99bf-b71a0780733c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2316, 0.0000, 0.0000,\n",
       "         0.0000, 1.3894, 0.0000, 0.0000, 0.0000, 0.5789, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5789, 0.0000, 0.2316, 0.0000, 0.0000, 0.6947,\n",
       "         0.1158, 0.0000, 0.1158, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.2316, 0.6947, 0.0000, 0.0000, 0.0000, 0.0000, 0.2316, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.9263, 0.2316, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 0.2316, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.1158, 1.1578, 0.0000, 0.0000, 0.0000, 0.2316, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.9263, 0.0000, 0.3473, 0.0000, 0.0000, 0.3473,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.8105, 0.0000, 0.2316, 0.0000, 0.8105, 0.0000, 0.9263, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.9263, 0.6947, 0.0000],\n",
       "        [0.0000, 0.0000, 0.0000, 0.5789, 0.0000, 0.1158, 0.0000, 0.0000, 0.6947,\n",
       "         0.0000, 0.3473, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4631, 0.0000, 1.6209, 0.0000, 0.4631, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.2316, 0.0000, 0.9263, 0.0000, 0.1158, 0.0000, 0.6947],\n",
       "        [0.2316, 0.5789, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9263,\n",
       "         0.0000, 0.0000, 0.4631, 0.8105, 0.0000, 0.0000, 0.0000],\n",
       "        [0.5789, 0.0000, 0.3473, 0.0000, 0.5789, 0.0000, 0.5789, 0.3473, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1158, 0.0000, 0.0000],\n",
       "        [0.0000, 0.0000, 1.0420, 0.0000, 0.0000, 0.0000, 0.0000, 1.7367, 0.0000,\n",
       "         0.0000, 0.1158, 1.2736, 0.0000, 0.0000, 0.0000, 0.3473],\n",
       "        [0.1158, 0.0000, 0.3473, 0.0000, 0.0000, 0.9263, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.3473, 1.0420, 0.5789],\n",
       "        [0.0000, 0.6947, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         1.0420, 0.0000, 0.0000, 0.0000, 0.6947, 0.0000, 0.4631],\n",
       "        [0.0000, 0.0000, 0.0000, 0.3473, 0.0000, 0.6947, 0.0000, 0.3473, 0.0000,\n",
       "         0.1158, 0.3473, 0.0000, 0.0000, 0.0000, 0.0000, 0.8105],\n",
       "        [0.0000, 0.1158, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.4631, 0.1158,\n",
       "         0.0000, 0.0000, 0.4631, 0.8105, 0.1158, 0.0000, 0.0000],\n",
       "        [0.5789, 0.0000, 0.0000, 0.5789, 0.4631, 0.3473, 0.9263, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1158, 0.4631, 0.0000]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FakeQuantOp.apply(q_model.fc2.weight.data, None, None, 4, 'asym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73fe8b-b293-4f7a-a92c-dd187a4cf2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a4f38-03c2-480f-9939-01adc1397946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
