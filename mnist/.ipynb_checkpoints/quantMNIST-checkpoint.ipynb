{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "583fd3a6-b9a0-44d6-b3bc-4699bef35c5e",
   "metadata": {},
   "source": [
    "# MNIST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47d5345d-ac54-4845-9be1-bff83185cf2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import namedtuple\n",
    "import copy\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a34062-b6ae-4e07-bbed-658d7c05525d",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b725318-c76b-45da-a04f-e2ebac8b9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '~/dataset'\n",
    "train_data = datasets.MNIST(root=dataset_dir, train=True,  download=True, transform=ToTensor())\n",
    "test_data  = datasets.MNIST(root=dataset_dir, train=False, download=True, transform=ToTensor())\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "# Number of trainData/validData/testData = 50000/10000/10000\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader  = DataLoader(test_data,  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdddba9e-3d46-49bd-8d02-e82b4b81999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualise(x, axs):\n",
    "\tx = x.view(-1).cpu().numpy()\n",
    "\taxs.hist(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966d9254-d9cf-4f28-b95d-92fa7df16fc7",
   "metadata": {},
   "source": [
    "# MNIST Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fccd9bff-19b3-45df-a200-20ca50454eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "class NN(nn.Module):\n",
    "\tdef __init__(self):\n",
    "\t\tsuper(NN, self).__init__()\n",
    "\t\tself.flatten = nn.Flatten()\n",
    "\t\tself.fc1 = nn.Linear(28*28, 16)\n",
    "\t\tself.fc2 = nn.Linear(16, 16)\n",
    "\t\tself.fc3 = nn.Linear(16, 10)\n",
    "\t\t\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.flatten(x)\n",
    "\t\tx = F.relu(self.fc1(x))\n",
    "\t\tx = F.relu(self.fc2(x))\n",
    "\t\tlogits = self.fc3(x)\n",
    "\n",
    "\t\treturn logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169b664c-17c4-4d34-ba3b-93497aa44698",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d80be6dd-b33a-4fb5-85d0-c32218d8d083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, model, loss_func, optimizer, epoch):\n",
    "\tmodel.train()\n",
    "\tmax_batch_index = int(np.floor(len(train_data)/batch_size))\n",
    "\tfor batch_index, (image, label) in enumerate(train_dataloader):\n",
    "\t\timage, label = image.to(device), label.to(device)\n",
    "\t\tpred = model(image)\n",
    "\t\tloss = loss_func(pred, label)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\t\t\n",
    "\t\tif batch_index == max_batch_index:\n",
    "\t\t\tprint(f'Epoch {epoch+1:<3d}: Loss: {loss.item():.2f}', end = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "079efc4f-7722-431f-86d4-c63b94bcebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_dataloader, model, loss_func, epoch):\n",
    "\tmodel.eval()\n",
    "\tloss, correct = 0, 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor image, label in test_dataloader:\n",
    "\t\t\timage, label = image.to(device), label.to(device)\n",
    "\t\t\tpred = model(image)\n",
    "\t\t\tloss += loss_func(pred, label).item()\n",
    "\t\t\tcorrect += (pred.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tloss /= len(test_dataloader.dataset)\n",
    "\tcorrect_rate = 100 * correct / len(test_dataloader.dataset)\n",
    "\tprint(f'Accuracy: {correct}/{len(test_data)} ({correct_rate:>.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae6c6141-94fe-4ee6-ad1e-4a59fe1db8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  : Loss: 1.05\tAccuracy: 7338/10000 (73.4%)\n",
      "Epoch 2  : Loss: 0.38\tAccuracy: 8519/10000 (85.2%)\n",
      "Epoch 3  : Loss: 0.28\tAccuracy: 8823/10000 (88.2%)\n",
      "Epoch 4  : Loss: 0.21\tAccuracy: 8952/10000 (89.5%)\n",
      "Epoch 5  : Loss: 0.17\tAccuracy: 9041/10000 (90.4%)\n",
      "Epoch 6  : Loss: 0.15\tAccuracy: 9094/10000 (90.9%)\n",
      "Epoch 7  : Loss: 0.13\tAccuracy: 9147/10000 (91.5%)\n",
      "Epoch 8  : Loss: 0.11\tAccuracy: 9177/10000 (91.8%)\n",
      "Epoch 9  : Loss: 0.10\tAccuracy: 9198/10000 (92.0%)\n",
      "Epoch 10 : Loss: 0.09\tAccuracy: 9240/10000 (92.4%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\tmodel = NN().to(device)\n",
    "\tloss_func = nn.CrossEntropyLoss()\n",
    "\toptimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\tepochs = 10\n",
    "\tfor epoch in range(epochs):\n",
    "\t\ttrain(train_dataloader, model, loss_func, optimizer, epoch)\n",
    "\t\ttest(test_dataloader, model, loss_func, epoch)\n",
    "\tprint(\"Done!\")\n",
    "\treturn model\n",
    "\n",
    "model = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01350b1-661b-44f3-bd40-9d6f2eb91552",
   "metadata": {},
   "source": [
    "# Quantization of Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b732b0-6fd7-4714-aa25-c79dfbba54b7",
   "metadata": {},
   "source": [
    "## Quantization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40788c28-5892-4c83-b4cd-85fe48720d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcScaleZeroPoint(min_val, max_val, num_bits=8, opt='asym'):\n",
    "\tqmin, qmax = 0., 2.**num_bits - 1.\n",
    "\tif opt == 'asym':\n",
    "\t\tscale = (max_val - min_val) / (qmax - qmin)\n",
    "\t\tinitial_zero_point = -min_val / scale\n",
    "\t\tzero_point = int({initial_zero_point < qmin: qmin,  initial_zero_point > qmax: qmax, qmin <= initial_zero_point <= qmax: initial_zero_point}.get(True, False))\n",
    "\tif opt == 'sym':\n",
    "\t\tscale = max(abs(min_val), abs(max_val)) / qmax\n",
    "\t\tzero_point = 0\n",
    "\treturn scale, zero_point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a8f4aa-1f98-4f3b-a11a-bbec3ca99868",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizeTensor(input_tensor, min_val=None, max_val=None, num_bits=8, opt='asym'):\n",
    "\tif not min_val and not max_val:\n",
    "\t\tmin_val, max_val = input_tensor.min(), input_tensor.max()\n",
    "\t\n",
    "\tqmin, qmax = 0., 2.**num_bits - 1.\n",
    "\tscale, zero_point = calcScaleZeroPoint(min_val, max_val, num_bits, opt)\n",
    "\t\n",
    "\tif opt == 'asym':\n",
    "\t\tquant_tensor = (input_tensor / scale + zero_point).clamp(qmin, qmax).round()\n",
    "\tif opt == 'sym':\n",
    "\t\tquant_tensor = (input_tensor / scale).clamp(qmax, qmax).round()\n",
    "\t\n",
    "\tqTuple = namedtuple('qTuple', ['tensor', 'scale', 'zero_point'])\n",
    "\treturn qTuple(tensor=quant_tensor, scale=scale, zero_point=zero_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "551f3c25-e727-4434-a601-f68e6e0cafba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dequantizeTensor(qTuple, opt='asym'):\n",
    "\tif opt == 'asym':\n",
    "\t\tdequant_tensor = qTuple.scale * (qTuple.tensor.float() - qTuple.zero_point)\n",
    "\tif opt == 'sym':\n",
    "\t\tdequant_tensor = qTuple.scale * (qTuple.tensor.float())\t\n",
    "\treturn dequant_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14b7e09c-4523-44da-bad9-44f53c86f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateStats(actTensor, stats, layerName):\n",
    "\t# dim=0 : find min/max in each col\n",
    "\t# dim=1 : find min/max in each row\n",
    "\tmaxValue = torch.max(actTensor, dim=1)[0]\n",
    "\tminValue = torch.min(actTensor, dim=1)[0]\n",
    "\t\n",
    "\tif layerName not in stats:\n",
    "\t\tstats[layerName] = {'max': maxValue.sum(), 'min': minValue.sum(), 'total': 1}\n",
    "\telse:\n",
    "\t\tstats[layerName]['max'] += maxValue.sum().item()\n",
    "\t\tstats[layerName]['min'] += maxValue.sum().item()\n",
    "\t\tstats[layerName]['total'] += 1\n",
    "\t\t\n",
    "\tweighting = 2.0 / (stats[layerName]['total']) + 1\n",
    "\n",
    "\tif 'ema_min' in stats[layerName]:\n",
    "\t\tstats[layerName]['ema_min'] = weighting*(minValue.mean().item()) + (1 - weighting) * stats[layerName]['ema_min']\n",
    "\telse:\n",
    "\t\tstats[layerName]['ema_min'] = weighting*(minValue.mean().item())\n",
    "\n",
    "\tif 'ema_max' in stats[layerName]:\n",
    "\t\tstats[layerName]['ema_max'] = weighting*(maxValue.mean().item()) + (1 - weighting) * stats[layerName]['ema_max']\n",
    "\telse: \n",
    "\t\tstats[layerName]['ema_max'] = weighting*(maxValue.mean().item())\n",
    "\n",
    "\t\tstats[layerName]['min_val'] = stats[layerName]['min']/ stats[layerName]['total']\n",
    "\t\tstats[layerName]['max_val'] = stats[layerName]['max']/ stats[layerName]['total']\n",
    "\n",
    "\treturn stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af59c4ae-3014-4e64-af00-c92eeb54b865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reworked Forward Pass to access activation Stats through updateStats function\n",
    "def gatherActivationStats(model, x, stats):\n",
    "\tx = model.flatten(x)\n",
    "\tstats = updateStats(x, stats, 'fc1')\n",
    "\tx = F.relu(model.fc1(x))\n",
    "\t\n",
    "\tstats = updateStats(x, stats, 'fc2')\n",
    "\tx = F.relu(model.fc2(x))\n",
    "\n",
    "\tstats = updateStats(x, stats, 'fc3')\n",
    "\tx = model.fc3(x)\n",
    "\n",
    "\treturn stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4865518a-d7ca-482d-a6e4-38cb8b9459e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry function to get stats of all functions.\n",
    "def gatherStats(model, testDataLoader):\n",
    "\tmodel.eval()\n",
    "\tstats = {}\n",
    "\twith torch.no_grad():\n",
    "\t\tfor img, lab in testDataLoader:\n",
    "\t\t\timg, lab = img.to(device), lab.to(device)\n",
    "\t\t\tstats = gatherActivationStats(model, img, stats)\n",
    "\n",
    "\tfinal_stats = {}\n",
    "\tfor key, value in stats.items():\n",
    "\t\tfinal_stats[key] = { \"max\" : value[\"max\"] / value[\"total\"], \"min\" : value[\"min\"] / value[\"total\"], \"ema_min\": value[\"ema_min\"], \"ema_max\": value[\"ema_max\"] }\n",
    "\treturn final_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c0986c97-c07a-4974-a2a2-7fc7e3eb2864",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FakeQuantOp(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, min_val=None, max_val=None, num_bits=8, opt='asym'):\n",
    "\t\t#def quantizeTensor(input_tensor, min_val=None, max_val=None, num_bits=4, opt='asym'):\n",
    "        x = quantizeTensor(x, min_val=min_val, max_val=max_val, num_bits=num_bits, opt=opt)\n",
    "        x = dequantizeTensor(x)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # straight through estimator\n",
    "        return grad_output, None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebd77813-e820-4f02-8feb-64bc5cd71b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantAwareTrainingForward(x, model, stats, act_quant=False, num_bits=8, opt='asym'):\n",
    "\tx = model.flatten(x)\n",
    "\t\n",
    "\tfc1_weight = model.fc1.weight.data\n",
    "\tmodel.fc1.weight.data = FakeQuantOp.apply(model.fc1.weight.data, None, None, num_bits, opt)\n",
    "# \tx = F.relu(model.fc1(x))\n",
    "\twith torch.no_grad():\n",
    "\t\tstats = updateStats(x.clone().view(x.shape[0], -1), stats, 'fc1')\n",
    "\tif act_quant:\n",
    "\t\tx = FakeQuantOp.apply(x, stats['fc1']['ema_min'], stats['fc1']['ema_max'], num_bits, opt)\n",
    "\tx = F.relu(model.fc1(x))\n",
    "\t\n",
    "\tfc2_weight = model.fc2.weight.data\n",
    "\tmodel.fc2.weight.data = FakeQuantOp.apply(model.fc2.weight.data, None, None, num_bits, opt)\n",
    "# \tx = F.relu(model.fc2(x))\n",
    "\twith torch.no_grad():\n",
    "\t\tstats = updateStats(x.clone().view(x.shape[0], -1), stats, 'fc2')\n",
    "\tif act_quant:\n",
    "\t\tx = FakeQuantOp.apply(x, stats['fc2']['ema_min'], stats['fc2']['ema_max'], num_bits, opt)\n",
    "\tx = F.relu(model.fc2(x))\n",
    "\n",
    "\tfc3_weight = model.fc3.weight.data\n",
    "\tmodel.fc3.weight.data = FakeQuantOp.apply(model.fc3.weight.data, None, None, num_bits, opt)\n",
    "# \tx = model.fc3(x)\n",
    "\twith torch.no_grad():\n",
    "\t\tstats = updateStats(x.clone().view(x.shape[0], -1), stats, 'fc3')\n",
    "\tif act_quant:\n",
    "\t\tx = FakeQuantOp.apply(x, stats['fc3']['ema_min'], stats['fc3']['ema_max'], num_bits, opt)\n",
    "\tx = model.fc3(x)\n",
    "\t\n",
    "#\treturn F.log_softmax(x, dim=1), fc1_weight, fc2_weight, fc3_weight, stats\n",
    "\treturn x, fc1_weight, fc2_weight, fc3_weight, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1801eb1c-e0df-473f-971f-8c8943c04f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainQAT(train_dataloader, model, loss_func, optimizer, epoch, stats, act_quant=False, num_bits=8, opt='asym'):\n",
    "\tmodel.train()\n",
    "\tmax_batch_index = int(np.floor(len(train_data)/batch_size))\n",
    "\tfor batch_index, (image, label) in enumerate(train_dataloader):\n",
    "\t\timage, label = image.to(device), label.to(device)\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\ty = model(image)\n",
    "\t\ty, fc1_weight, fc2_weight, fc3_weight, stats = quantAwareTrainingForward(image, model, stats, act_quant, num_bits, opt)\n",
    "\t\t\n",
    "\t\t# Recover FP32 to improve accuracy\n",
    "# \t\tmodel.fc1.weight.data = fc1_weight\n",
    "# \t\tmodel.fc2.weight.data = fc2_weight\n",
    "# \t\tmodel.fc3.weight.data = fc3_weight\n",
    "\n",
    "\t\tloss = loss_func(y, label)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\t\t\n",
    "\t\tif batch_index == max_batch_index:\n",
    "\t\t\tprint(f'Epoch {epoch+1:<3d}: Loss: {loss.item():.2f}', end = '\\t')\n",
    "\t\t\t\n",
    "\treturn stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16fb3bab-b0f9-4515-80fe-bbb156cbc867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testQAT(test_dataloader, model, epoch, loss_func, stats, act_quant=False, num_bits=8, opt='asym'):\n",
    "\tmodel.eval()\n",
    "\tloss, correct = 0, 0\n",
    "\twith torch.no_grad():\n",
    "\t\tfor image, label in test_dataloader:\n",
    "\t\t\timage, label = image.to(device), label.to(device)\n",
    "\t\t\ty, _, _, _, _ = quantAwareTrainingForward(image, model, stats, act_quant, num_bits, opt)\t\n",
    "\t\t\tloss += loss_func(y, label).item()\n",
    "\t\t\tcorrect += (y.argmax(1) == label).type(torch.int).sum().item()\n",
    "\tloss /= len(test_dataloader.dataset)\n",
    "\tcorrect_rate = 100 * correct / len(test_dataloader.dataset)\n",
    "\tprint(f'Accuracy: {correct}/{len(test_data)} ({correct_rate:>.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "951d6389-bfeb-4828-8dec-563dc75dbde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainQAT():\n",
    "\tmodel = NN().to(device)\n",
    "\tloss_func = nn.CrossEntropyLoss()\n",
    "\toptimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "\t\n",
    "\tepochs = 15\n",
    "\tnum_bits = 8\n",
    "\tstats = {}\n",
    "\topt = 'asym'\n",
    "\tfor epoch in range(epochs):\n",
    "\t\tact_quant = True if epoch > 5 else False\n",
    "\t\t#def trainQAT(train_dataloader, model, loss_func, optimizer, epoch, stats, act_quant=False, num_bits=8, opt='asym'):\n",
    "\t\tstats = trainQAT(train_dataloader, model, loss_func, optimizer, epoch, stats, act_quant, num_bits, opt)\n",
    "\t\ttestQAT(test_dataloader, model, epoch, loss_func, stats, act_quant, num_bits, opt)\n",
    "\tprint(\"Done!\")\n",
    "\treturn model, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87681f61-fcf6-4799-985b-5f45d420bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1  : Loss: 2.05\tAccuracy: 3719/10000 (37.2%)\n",
      "Epoch 2  : Loss: 0.94\tAccuracy: 6901/10000 (69.0%)\n",
      "Epoch 3  : Loss: 0.57\tAccuracy: 7818/10000 (78.2%)\n",
      "Epoch 4  : Loss: 0.43\tAccuracy: 8261/10000 (82.6%)\n",
      "Epoch 5  : Loss: 0.33\tAccuracy: 8472/10000 (84.7%)\n",
      "Epoch 6  : Loss: 0.28\tAccuracy: 8622/10000 (86.2%)\n",
      "Epoch 7  : Loss: 0.35\tAccuracy: 8055/10000 (80.5%)\n",
      "Epoch 8  : Loss: 0.41\tAccuracy: 8060/10000 (80.6%)\n",
      "Epoch 9  : Loss: 0.44\tAccuracy: 7584/10000 (75.8%)\n",
      "Epoch 10 : Loss: 0.34\tAccuracy: 8352/10000 (83.5%)\n",
      "Epoch 11 : Loss: 0.45\tAccuracy: 7826/10000 (78.3%)\n",
      "Epoch 12 : Loss: 0.35\tAccuracy: 8452/10000 (84.5%)\n",
      "Epoch 13 : Loss: 0.30\tAccuracy: 8401/10000 (84.0%)\n",
      "Epoch 14 : Loss: 0.31\tAccuracy: 8260/10000 (82.6%)\n",
      "Epoch 15 : Loss: 0.39\tAccuracy: 8113/10000 (81.1%)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "q_model, old_stats = mainQAT()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00aff51b-eec0-4568-ba99-55daa00f9a89",
   "metadata": {},
   "source": [
    "## Rework Forward pass of Linear and Conv Layers to support Quantisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "944b011b-7872-49ed-8277-41448829cc46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1623/10000 (16.2%)\n"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "testQAT(test_dataloader, model, epoch=10, loss_func=loss_func, stats=old_stats, act_quant=True, num_bits=8, opt='asym')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15ac1184-ea39-4ff6-b612-7de355a959c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0154, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0026, 0.0129, 0.0347,  ..., 0.0296, 0.0051, 0.0322],\n",
       "        [0.0322, 0.0270, 0.0077,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0077, 0.0180,  ..., 0.0180, 0.0077, 0.0129],\n",
       "        [0.0000, 0.0322, 0.0000,  ..., 0.0026, 0.0000, 0.0193],\n",
       "        [0.0051, 0.0051, 0.0000,  ..., 0.0193, 0.0000, 0.0051]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight = model.state_dict()['fc1.weight']\n",
    "weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c625529d-2395-455e-99f0-08e96b542412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qTuple(tensor=tensor([[ 0., 12.,  0.,  ...,  0.,  0.,  0.],\n",
       "        [ 2., 10., 27.,  ..., 23.,  4., 25.],\n",
       "        [25., 21.,  6.,  ...,  0.,  0.,  0.],\n",
       "        ...,\n",
       "        [ 0.,  6., 14.,  ..., 14.,  6., 10.],\n",
       "        [ 0., 25.,  0.,  ...,  2.,  0., 15.],\n",
       "        [ 4.,  4.,  0.,  ..., 15.,  0.,  4.]], device='cuda:0'), scale=tensor(0.0013, device='cuda:0'), zero_point=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa = quantizeTensor(weight)\n",
    "aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67e6b3d8-d10b-4604-b537-c3ae1015609e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.0154, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        [0.0026, 0.0129, 0.0347,  ..., 0.0296, 0.0051, 0.0322],\n",
       "        [0.0322, 0.0270, 0.0077,  ..., 0.0000, 0.0000, 0.0000],\n",
       "        ...,\n",
       "        [0.0000, 0.0077, 0.0180,  ..., 0.0180, 0.0077, 0.0129],\n",
       "        [0.0000, 0.0322, 0.0000,  ..., 0.0026, 0.0000, 0.0193],\n",
       "        [0.0051, 0.0051, 0.0000,  ..., 0.0193, 0.0000, 0.0051]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dequantizeTensor(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35fcaa9a-207f-4578-9899-b8745615549a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[0.0000, 0.0154, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                      [0.0026, 0.0129, 0.0347,  ..., 0.0296, 0.0051, 0.0322],\n",
       "                      [0.0322, 0.0270, 0.0077,  ..., 0.0000, 0.0000, 0.0000],\n",
       "                      ...,\n",
       "                      [0.0000, 0.0077, 0.0180,  ..., 0.0180, 0.0077, 0.0129],\n",
       "                      [0.0000, 0.0322, 0.0000,  ..., 0.0026, 0.0000, 0.0193],\n",
       "                      [0.0051, 0.0051, 0.0000,  ..., 0.0193, 0.0000, 0.0051]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([ 0.2936, -0.0185,  0.0640, -0.0622, -0.1085,  0.0395,  0.0342, -0.0214,\n",
       "                      -0.0931,  0.3520,  0.0525,  0.0952, -0.2434, -0.0094, -0.0345,  0.2193],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[0.1095, 0.0000, 0.1725, 0.1593, 0.1294, 0.3716, 0.0465, 0.5707, 0.5973,\n",
       "                       0.4413, 0.4347, 0.0133, 0.0000, 0.0000, 0.1228, 0.0000],\n",
       "                      [0.4280, 0.1593, 0.1228, 0.0000, 0.0398, 0.0000, 0.1526, 0.0000, 0.0000,\n",
       "                       0.0398, 0.8461, 0.4612, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "                      [0.1029, 0.1792, 0.0000, 0.0000, 0.2953, 0.0630, 0.0000, 0.4612, 0.0133,\n",
       "                       0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1792, 0.5906],\n",
       "                      [0.0000, 0.0000, 0.0000, 0.0000, 0.0066, 0.3086, 0.0000, 0.0564, 0.0000,\n",
       "                       0.0697, 0.0000, 0.0000, 0.0265, 0.0000, 0.0962, 0.2621],\n",
       "                      [0.0000, 0.0000, 0.6935, 0.0000, 0.3650, 0.0000, 0.0000, 0.0000, 0.5442,\n",
       "                       0.1460, 0.0199, 0.0000, 0.7433, 0.1593, 0.0630, 0.4612],\n",
       "                      [0.0000, 0.0697, 0.0000, 0.1095, 0.0000, 0.4181, 0.2124, 0.0000, 0.0000,\n",
       "                       0.3086, 0.0000, 0.0000, 0.0000, 0.3451, 0.0000, 0.3783],\n",
       "                      [0.0000, 0.0564, 0.7300, 0.0000, 0.0000, 0.0000, 0.3849, 0.0000, 0.3451,\n",
       "                       0.3982, 0.0000, 0.0000, 0.5143, 0.3285, 0.0000, 0.1924],\n",
       "                      [0.3584, 0.0763, 0.4048, 0.2190, 0.0000, 0.0000, 0.3086, 0.5973, 0.0000,\n",
       "                       0.0000, 0.4413, 0.0000, 0.0763, 0.0000, 0.2555, 0.4479],\n",
       "                      [0.2489, 0.0000, 0.1360, 0.0000, 0.0000, 0.0133, 0.3384, 0.0000, 0.0000,\n",
       "                       0.4679, 0.0199, 0.1161, 0.0000, 0.0000, 0.0000, 0.2489],\n",
       "                      [0.2422, 0.0000, 0.0000, 0.0000, 0.0000, 0.2688, 0.0000, 0.5906, 0.0000,\n",
       "                       0.6470, 0.0000, 0.5707, 0.6039, 0.1460, 0.0000, 0.1593],\n",
       "                      [0.0000, 0.1659, 0.0000, 0.1924, 0.6935, 0.4347, 0.0000, 0.0000, 0.1460,\n",
       "                       0.0000, 0.0000, 0.2754, 0.5442, 0.7034, 0.0000, 0.4944],\n",
       "                      [0.0000, 0.2256, 0.0066, 0.0000, 0.0000, 0.0000, 0.1394, 0.0000, 0.0697,\n",
       "                       0.0000, 0.0000, 0.0465, 0.0000, 0.0000, 0.0000, 0.1593],\n",
       "                      [0.0000, 0.2820, 0.3451, 0.2356, 0.4811, 0.2820, 0.0000, 0.4048, 0.1029,\n",
       "                       0.0000, 0.4479, 0.0000, 0.2057, 0.0000, 0.0000, 0.0000],\n",
       "                      [0.6802, 0.0000, 0.0000, 0.0398, 0.0697, 0.1924, 0.0000, 0.0000, 0.0000,\n",
       "                       0.0000, 0.3716, 0.0630, 0.1161, 0.1360, 0.1526, 0.4878],\n",
       "                      [0.7233, 0.2057, 0.0000, 0.0000, 0.1593, 0.2887, 0.0896, 0.3384, 0.1228,\n",
       "                       0.5906, 0.0000, 0.0000, 0.0000, 0.2953, 0.2820, 0.0000],\n",
       "                      [0.0000, 0.0000, 0.3219, 0.0000, 0.3086, 0.3152, 0.0000, 0.4811, 0.0000,\n",
       "                       0.4181, 0.0000, 0.1725, 0.0000, 0.0896, 0.0000, 0.4811]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.2459,  0.2184, -0.0154,  0.1573,  0.1869,  0.1514,  0.3712,  0.1842,\n",
       "                       0.3986,  0.0474,  0.1425, -0.2032, -0.3476,  0.3198,  0.3922,  0.0198],\n",
       "                     device='cuda:0')),\n",
       "             ('fc3.weight',\n",
       "              tensor([[0.5186, 0.1161, 0.0000, 0.1625, 0.6734, 0.0000, 0.5496, 0.0000, 0.0000,\n",
       "                       0.0000, 0.0000, 0.0000, 0.2438, 0.0000, 0.0000, 0.0000],\n",
       "                      [0.0000, 0.0000, 0.4605, 0.4296, 0.0000, 0.5805, 0.0000, 0.0000, 0.1974,\n",
       "                       0.1742, 0.1393, 0.0077, 0.0000, 0.0774, 0.0000, 0.6192],\n",
       "                      [0.0929, 0.0000, 0.0000, 0.0774, 0.3212, 0.0000, 0.1625, 0.0000, 0.0000,\n",
       "                       0.0774, 0.9869, 0.0232, 0.1238, 0.3599, 0.0000, 0.0000],\n",
       "                      [0.0000, 0.0000, 0.2438, 0.0000, 0.4760, 0.0000, 0.4683, 0.2438, 0.0000,\n",
       "                       0.5263, 0.0000, 0.1393, 0.0000, 0.2670, 0.3444, 0.0000],\n",
       "                      [0.0619, 0.6579, 0.0000, 0.1742, 0.0000, 0.0000, 0.0000, 0.5883, 0.4683,\n",
       "                       0.4141, 0.0000, 0.2438, 0.0000, 0.3290, 0.0000, 0.0000],\n",
       "                      [0.0000, 0.2903, 0.0000, 0.1625, 0.2903, 0.1742, 0.7508, 0.6115, 0.6889,\n",
       "                       0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1161, 0.2129],\n",
       "                      [0.0000, 0.7740, 0.0000, 0.0000, 0.0929, 0.0619, 0.0232, 0.2670, 0.0000,\n",
       "                       0.0000, 0.0851, 0.0929, 0.0387, 0.6889, 0.0000, 0.0000],\n",
       "                      [0.3831, 0.0542, 0.1819, 0.0000, 0.0000, 0.3754, 0.0000, 0.0000, 0.2903,\n",
       "                       0.5650, 0.3290, 0.0000, 0.0000, 0.0000, 0.8321, 0.0000],\n",
       "                      [0.0542, 0.0000, 0.0697, 0.0000, 0.4528, 0.0000, 0.0000, 0.3290, 0.0000,\n",
       "                       0.3754, 0.0000, 0.1084, 0.5728, 0.0000, 0.0000, 0.5650],\n",
       "                      [0.4915, 0.0000, 0.3754, 0.0774, 0.0000, 0.2361, 0.0000, 0.3909, 0.0387,\n",
       "                       0.0000, 0.0000, 0.0000, 0.3754, 0.0387, 0.6579, 0.0774]],\n",
       "                     device='cuda:0')),\n",
       "             ('fc3.bias',\n",
       "              tensor([ 0.0395, -0.1395,  0.2172,  0.0315,  0.1462,  0.1778,  0.1878,  0.0924,\n",
       "                      -0.3997, -0.0125], device='cuda:0'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75517c42-e301-488b-9b28-098823b53667",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantizeLayer(qActTuple, layer, stat, numBits=4, opt='asym'):\n",
    "\tW, B = layer.weight.data, layer.bias.data\n",
    "\t\n",
    "\tqWeightTuple = quantizeTensor(W, numBits=numBits, opt=opt)\n",
    "\tqBiasTuple   = quantizeTensor(B, numBits=numBits, opt=opt)\n",
    "\t\n",
    "\tlayer.weight.data = qWeightTuple.qTensor.float()\n",
    "\tlayer.bias.data   = qBiasTuple.qTensor.float()\n",
    "\t\n",
    "\tnextScale, nextZeroPoint = calcScaleZeroPoint(minValue=stat['min'], maxValue=stat['max'], numBits=numBits, opt=opt)\n",
    "\t\n",
    "\tweightScale = qWeightTuple.scale\n",
    "\tweightZeroPoint = qWeightTuple.zeroPoint\n",
    "\t\n",
    "\tif opt == 'asym':\n",
    "\t\tlayer.weight.data = ((qWeightTuple.scale * qActTuple.scale) / nextScale) * (layer.weight.data - qWeightTuple.zeroPoint)\n",
    "\t\tlayer.bias.data = (qBiasTuple.scale / nextScale) * (layer.bias.data - qBiasTuple.zeroPoint)\t\t\n",
    "\t\toAct = layer(qActTuple.qTensor.float() - qActTuple.zeroPoint) + nextZeroPoint\n",
    "\tif opt == 'sym':\n",
    "\t\tlayer.weight.data = ((qWeightTuple.scale * qActTuple.scale) / nextScale) * (layer.weight.data)\n",
    "\t\tlayer.bias.data = (qBiasTuple.scale / nextScale) * (layer.bias.data)\n",
    "\t\toAct = layer(qActTuple.qTensor.float())\n",
    "\t\t\n",
    "\tlayer.weight.data, layer.bias.data = W, B\n",
    "\t\n",
    "\treturn oAct.round(), nextScale, nextZeroPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96b34509-aadf-4e11-9c60-7495f367f90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantForward(x, model, stats, num_bits=8, opt='asym'):\n",
    "\t# Quantise before inputting into incoming layers\n",
    "\tx = quantizeTensor()\n",
    "\tif sym:\n",
    "\t\tx = quantize_tensor_sym(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'], num_bits=num_bits)\n",
    "\telse:\n",
    "\t\tx = quantize_tensor(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'], num_bits=num_bits)\n",
    "\n",
    "\tx, scale_next, zero_point_next = quantizeLayer(x.tensor, model.conv1, stats['conv2'], x.scale, x.zero_point, vis, axs, X=X, y=y+1, sym=sym, num_bits=num_bits)\n",
    "\n",
    "\tx = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "\n",
    "\n",
    "\tx, scale_next, zero_point_next = quantizeLayer(x, model.conv2, stats['fc1'], scale_next, zero_point_next, vis, axs, X=X, y=y+3, sym=sym, num_bits=num_bits)\n",
    "\n",
    "\tx = F.max_pool2d(x, 2, 2)\n",
    "\n",
    "\n",
    "\tx = x.view(-1, 4*4*50)\n",
    "\n",
    "\tx, scale_next, zero_point_next = quantizeLayer(x, model.fc1, stats['fc2'], scale_next, zero_point_next, vis, axs, X=X+1, y=0, sym=sym, num_bits=num_bits)\n",
    "\n",
    "\n",
    "\t# Back to dequant for final layer\n",
    "# \tif sym:\n",
    "# \t\tx = dequantize_tensor_sym(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "# \telse:\n",
    "# \t\tx = dequantize_tensor(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n",
    "\n",
    "\n",
    "\tx = model.fc2(x)\n",
    "\n",
    "\tif vis:\n",
    "\t\taxs[X+1,3].set_xlabel('Unquantised Weights of fc2 layer')\n",
    "\t\tvisualise(model.fc2.weight.data,axs[X+1,3])\n",
    "\n",
    "\t\taxs[X+1,2].set_xlabel('Output after fc2 but dequantised visualised below: ')\n",
    "\t\tvisualise(x,axs[X+1,4])\n",
    "\n",
    "\treturn F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8ae37e-fa48-4b07-99bf-b71a0780733c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b73fe8b-b293-4f7a-a92c-dd187a4cf2a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a4f38-03c2-480f-9939-01adc1397946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
